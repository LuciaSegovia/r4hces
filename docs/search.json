[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Household Consumption and Expenditure Surveys",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "index.html#about-this-manual",
    "href": "index.html#about-this-manual",
    "title": "R for Household Consumption and Expenditure Surveys",
    "section": "About this manual",
    "text": "About this manual\nThis manual is designed for absolute beginners who are interested in using R and RStudio for nutrition analysis of household consumption and expenditure surveys(HCES). The manual is an adaptation of materials for statistical analysis of HCES developed by the Micronutrient Action Policy Support(MAPS) Project and made available to all for use, without warranty or liability. The MAPS project is funded by the Bill and Melinda Gates Foundation."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "R for Household Consumption and Expenditure Surveys",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe would like to thank the following people for their contributions to this manual:\nLiberty Mlambo, Lucia Sergovia de la Revilla, Thomas Codd,Gareth Osman, Kevin Tang, Tineka Blake, Edward Joy, Louise E. Ander"
  },
  {
    "objectID": "index.html#who-is-this-manual-for",
    "href": "index.html#who-is-this-manual-for",
    "title": "R for Household Consumption and Expenditure Surveys",
    "section": "Who is this manual for?",
    "text": "Who is this manual for?\nThe goal of this manual is to provide a comprehensive introduction to these powerful technologies and to teach you how to use them to better understand your data and collaborate with others on your project.\nThroughout this manual, you will learn how to install and set up R and RStudio on your computer, as well as how to use them to perform data analysis, create visualizations, and manage your code. The manual includes step-by-step instructions, examples, and practice exercises to help you master these technologies.\nWhether you are a researcher, data scientist, or statistician, this manual will provide you with the skills and knowledge you need to start using R and RStudio for HCES analysis, to better understand your data and collaborate with others on your project.\nIt is important to note that this manual is not a comprehensive guide to R and RStudio but rather an introduction, designed to give you the foundational knowledge to start working with these technologies. There are many other resources available for learning more about these technologies, including online tutorials, forums, and documentation.\nWe hope you find this manual helpful and that it empowers you to work with these powerful tools."
  },
  {
    "objectID": "intro.html#software-requirements",
    "href": "intro.html#software-requirements",
    "title": "1  Introduction",
    "section": "1.1 Software requirements",
    "text": "1.1 Software requirements\nFirst, we will cover R, which is a powerful and versatile programming language that is widely used for data analysis, statistical modeling, and data visualization.\n\nIt is an open-source software that can be freely downloaded and used by anyone. R is widely used in academia, industry, and government, and is becoming increasingly popular among data scientists and analysts.\nIt is a great tool for those who have been using other statistics tools like Excel, SAS, SPSS and want to take their data analysis skills to the next level.\n\nThis training will provide an introduction to the basics of R and will give you the skills you need to start working with data in R..\nNext, we will introduce RStudio, which is a popular integrated development environment (IDE) for R.\n\nRStudio provides a user-friendly interface for working with R and makes it easy to work with R packages, which are collections of pre-written R code that can be used to perform specific tasks.\nWith RStudio, you will be able to write, test, and debug your R code, and easily share your work with others.\n\n\n\n\nsource: https://moderndive.netlify.app/1-getting-started.html\n\n\nThis manual will provide step-by-step instructions for installing and setting up R and RStudio on your computer. We will also go over basic concepts and commands for working with each technology, as well as provide examples of how to use them in different contexts. With this manual, you will have the skills and knowledge you need to start using these powerful technologies to better understand your data and collaborate with others on your project."
  },
  {
    "objectID": "intro.html#downloading-and-installing-r-and-rstudio",
    "href": "intro.html#downloading-and-installing-r-and-rstudio",
    "title": "1  Introduction",
    "section": "1.2 Downloading and Installing R and Rstudio",
    "text": "1.2 Downloading and Installing R and Rstudio\n\n\n1.2.1 Downloading and Installing R\n\nTo download R, you can visit the official R website at https://cran.r-project.org/. On the website, you will see links to download the latest version of R for Windows, Mac, and Linux. Once you have downloaded the installer for your operating system, you can run the installer and follow the prompts to install R on your computer.\nDownloading and installing R:\n\n\n\n\n\n\nInstructions for downloading and Installing R\n\n\n\n\n\nStep 1:\n\nStep 2:\n\nStep 3:\n\nStep 4:\n\nStep 5:\n\nStep 6:\n\nStep 7:\n\nStep 8:\n\n\n\n\n\n\n1.2.2 Downloading and Installing RStudio\nTo download RStudio, you can visit the official RStudio website at https://posit.co/download/rstudio-desktop/. On the website, you will see links to download the latest version of RStudio for Windows, Mac, and Linux. Once you have downloaded the installer for your operating system, you can run the installer and follow the prompts to install RStudio on your computer. \n\n\n\n\n\n\nInstructions for downloading and Installing Rstudio\n\n\n\n\n\nStep 1: Navigate to https://posit.co/download/rstudio-desktop/\n\nStep 2:\n\nStep 3:\n\nStep 4:\n\n\n\n\nPlease note that these are general instructions for a Microsoft Windows operating system, and depending on your system setup and security settings, some steps might be slightly different. Also, you will need to make sure that you have administrative access or permission to install the software on your computer.\nYou can also refer to the software website instruction or online tutorials that are specific to your operating system and setup.\nFrom here we will use the term R to refer to R and Rstudio or vice-versa.\n\n\n\nSource: https://docs.posit.co/ide/user/ide/guide/ui/ui-panes.html"
  },
  {
    "objectID": "intro.html#recommended-setup-while-using-this-book",
    "href": "intro.html#recommended-setup-while-using-this-book",
    "title": "1  Introduction",
    "section": "1.3 Recommended setup while using this book",
    "text": "1.3 Recommended setup while using this book\nStep 1: Download the training files from the following link: https://dzvoti.github.io/r4hces/r4hces-data.zip\nStep 2: Unzip the file and save it in a folder on your computer.\nStep 3: Open RStudio create a new project using an existing folder. Select the folder where you saved the training files."
  },
  {
    "objectID": "data_types.html#assignment",
    "href": "data_types.html#assignment",
    "title": "2  Data Types",
    "section": "2.1 Assignment",
    "text": "2.1 Assignment\nWe can store any of these datatypes in an object by assigning the value to that object. For example, we can assign the value Maize to the object food_name as follows:\n\nfood_name <- \"Maize\"\n\nThe <- is the assignment operator. It assigns the value on the right to the object on the left. We can then use the object food_name in other commands, for example, to print the value of food_name we can use the print() function:\n\nprint(food_name)\n\nThere are other assignment operators, such as = and ->, but <- is the most common. We can also assign the value of an object to another object, for example:\n\nfood_name2 <- food_name\n\nIn this case, the value of food_name is assigned to food_name2. We can then print the value of food_name2:\n\nprint(food_name2)\n\nIn this book we will use the <- and the = assignment operator. We use the <- when we want to assign a value to an object, and the = when we want to assign a value to an argument in a function. This is a convention that is used by many R programmers. More on functions later."
  },
  {
    "objectID": "data_types.html#character-data",
    "href": "data_types.html#character-data",
    "title": "2  Data Types",
    "section": "2.2 Character data",
    "text": "2.2 Character data\nThe simplest data type in R is the character. A character is a string of characters, for example, the “Maize” name that we assigned above. The “” indicate that we want to store the string of characters between the “” in the object. If we don’t use the “” then R will look for an object with that name, and if it doesn’t find it, it will throw an error. For example, if we type:\n\nfood_name <- Maize\n\nWe can fix this by putting the “” around the string of characters:\n\nfood_name <- \"Maize\"\n\nWe ca perform operations on character data, such as concatenation, which is the joining of two or more strings of characters. We can do this using the paste() function. For example, we can create a new character object called food_name3 by concatenating the values of food_name and food_name2 as follows:\n\n# Create character vector with value \"Maize\"\nfood_name <- \"Maize\"\n# Create character vector with value \"Meal\"\nfood_name2 <- \"Meal\"\n# Concatenate the values of food_name and food_name2 and assign the result to a new character object called food_name3\nfood_name3 <- paste(food_name, food_name2)\n# Print the value of food_name3\nprint(food_name3)"
  },
  {
    "objectID": "data_types.html#numeric-data",
    "href": "data_types.html#numeric-data",
    "title": "2  Data Types",
    "section": "2.3 Numeric data",
    "text": "2.3 Numeric data\nA numeric is a numerical value, such as the food quantity value. We can assign a numeric value to an object as follows:\n\nfood_quantity <- 0.5\n\nNote that we don’t need to put the “” around the numeric value. If we do, then R will treat it as a character, and not a numeric. For example, if we type:\n\nfood_quantity <- \"0.5\"\n\nWe can then do simple mathematical manipulations with a numeric value. For example, we can add 0.5 to the value of food_quantity as follows:\n\nfood_quantity <- 0.5\n# Add 0.5 to the value of food_quantity\nfood_quantity <- food_quantity + 0.5\n\n\n\n\n\n\n\nExercise\n\n\n\n\nCreate a character object called food_name and assign it the value \"Maize\".\nCreate another character object called food_subname and assign it the value \"Meal\".\nContatenate the values of food_name and food_subname and assign the result to a new character object called full_name.\nCreate a numeric object called food_quantity_g and assign it the value 15.\nConvert the value of food_quantity_g to milligrams and assign the result to a new numeric object called food_quantity_mg.\n\n\n\n\n2.3.1 Operations on numeric data\nWe can perform operations on numeric data, such as addition, subtraction, multiplication and division. For example, we can create a new numeric object called food_quantity by adding the values of food_quantity_g and food_quantity_mg as follows:\n\n# Create a numeric object called food_quantity_g and assign it the value 15\nfood_quantity_g <- 15\n\n# Create a numeric object called food_quantity_mg and \n# calculate the value of food_quantity_g in milligrams\nfood_quantity_mg <- food_quantity_g * 1000\n\nJust like in maths the operators in R follow operator precedence.However we can use brackets to specify the order of operations."
  },
  {
    "objectID": "data_types.html#logical-data",
    "href": "data_types.html#logical-data",
    "title": "2  Data Types",
    "section": "2.4 Logical data",
    "text": "2.4 Logical data\nLogical data takes the values TRUE or FALSE. We can assign a logical value to an object as follows:\n\nis_staple <- TRUE\n\nLogical values can be returned from oparation e.g. testing for equality. For example, we can test whether the vales in two objects is the same as follow:\n\n# Create character vectors\nfood_name <- \"Maize\"\nfood_name2 <- \"Maize\"\nfood_name3 <- \"Rice\"\n\n# Test equality\nfood_name == food_name2\nfood_name == food_name3\n\nThis brings us to the earlier point that we made that 15 is not equal to \"15\" in R.\n\n# Assign numeric values to object\nfood_quantity_g <- 15\nfood_quantity_g2 <- \"15\"\n# Test equality\nfood_quantity_g == food_quantity_g2\n\nNotice how when testing for equality we use ==? This is because the = is an assignment operator and not a logical operator. We can also use the != operator to test for inequality. For example, we can test whether the values in two objects are not the same as follows:\n\nfood_name != food_name2\nfood_name != food_name3\n\nOther logical operators are >, <, >= and <=. Logical object can be the subject of logical functions, notably \"if .. then\". Consider the example below:\n\n# Create numeric object\nage <- 18\n# Test whether age is greater than 18\nif(age > 18) {\n    print(\"You are an adult\")\n    }else{\n        print(\"You are not an adult\")\n        }\n\nTesting the same example with a different value of age:\n\n# Create numeric object\nage <- 17\n# Test whether age is greater than 18\nif(age > 18) {\n    print(\"You are an adult\")\n    }else{\n        print(\"You are not an adult\")\n        }\n\nLogical operations can be chained together using the & operator for \"and\" and the | operator for \"or\". For example, we can test whether the values in two objects are the same and whether the value of food_quantity_g is greater than 10 as follows:\n\nfood_name == food_name2 & food_quantity_g > 10"
  },
  {
    "objectID": "data_types.html#summary",
    "href": "data_types.html#summary",
    "title": "2  Data Types",
    "section": "2.5 Summary",
    "text": "2.5 Summary\nUntil now we have been storing only one value in an object. We can store multiple values in an object using a vector. We will look at vectors and data structures in the next section."
  },
  {
    "objectID": "data_structures.html#vectors",
    "href": "data_structures.html#vectors",
    "title": "3  Data Structures",
    "section": "3.1 Vectors",
    "text": "3.1 Vectors\nA vector is a series of homogeneous values of a variable (e.g. Foods from an HCES survey). The easiest way to form a vector of values in R is with the \"combine\" function c(). An example of a vector of character values (food_names) is shown below:\n\n# Create a vector of character values\nfood_names <-\n    c(\"Rice\",\n      \"Maize\",\n      \"Beans\",\n      \"Cassava\",\n      \"Potatoes\",\n      \"Sweet potatoes\",\n      \"Wheat\")\n\n#Create a vector of numeric values\nconsumpution <- c(0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.01)\n\n# Create a vector of logical values\nis_staple <- c(TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE)\n\n# Create a vector of mixed values\nmixture <- c(5.2, TRUE, \"CA\")\n\n\n\n\n\n\n\nExcercise\n\n\n\nUse print to see the values of the vectors above e.g print(food_names) What happens if you try to print the vector mixture?\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe can count the number of items in a vector with the length() function:\n\nlength(food_names)\n\n[1] 7\n\n\nEach item in a vector can be referenced by its index (i.e. its position in the sequence of values), and we can pull out a particular item using the square brackets after the vector name. For example, the 3rd item in food_names can be accessed like this\n\nfood_names[3]\n\n[1] \"Beans\""
  },
  {
    "objectID": "data_structures.html#data-frames-vs-tibbles",
    "href": "data_structures.html#data-frames-vs-tibbles",
    "title": "3  Data Structures",
    "section": "3.2 data frames vs tibbles",
    "text": "3.2 data frames vs tibbles\nIn R, data frames and tibbles are two common data structures used to store tabular data. While they are similar in many ways, there are some important differences to keep in mind.\n\n3.2.1 Data Frames\nData frames are a built-in R data structure that is used to store tabular data. They are similar to matrices, but with the added ability to store columns of different data types. Data frames are created using the data.frame() function, and can be manipulated using a variety of built-in R functions.\n\n\n3.2.2 Tibbles\nTibbles are a newer data structure that were introduced as part of the tidyverse package. They are similar to data frames, but with some important differences. Tibbles are created using the tibble() function, and can also be manipulated using a variety of built-in tidyverse functions.\nOne of the main differences between data frames and tibbles is how they handle column names. In a data frame, column names are stored as a character vector, and can be accessed using the $ operator. In a tibble, column names are stored as a special type of object called a quosure, which allows for more flexible and consistent handling of column names.\nAnother difference between data frames and tibbles is how they handle subsetting. In a data frame, subsetting using the [ ] operator can sometimes lead to unexpected results, especially when subsetting a single column. In a tibble, subsetting is more consistent and predictable, and is done using the [[ ]] operator or with user friendly dplyr function e.g. filter, select.\nOverall, while data frames and tibbles are similar in many ways, tibbles offer some important advantages over data frames, especially when working with the tidyverse package.\nLet us make a data frame using the data.frame() function. We will use the vectors we created above as the columns of the data frame. Note that the vectors must be of the same length, otherwise the data frame will be filled with NA values to make up the difference.\n\n# Create a data frame\nfood_df <-\n    data.frame(\n        food_names = c(\n            \"Rice\",\n            \"Maize\",\n            \"Beans\",\n            \"Cassava\",\n            \"Potatoes\",\n            \"Maize\",\n            \"Wheat\"\n        ),\n        consumption = c(0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.01),\n        is_staple = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE),\n        stringsAsFactors = TRUE\n    )\n\n# Print the data frame\nprint(food_df)\n\n  food_names consumption is_staple\n1       Rice        0.50      TRUE\n2      Maize        0.40      TRUE\n3      Beans        0.30      TRUE\n4    Cassava        0.20      TRUE\n5   Potatoes        0.10     FALSE\n6      Maize        0.05      TRUE\n7      Wheat        0.01     FALSE\n\n\nLet us make a tibble using the tibble() function. We will use the vectors we created above as the columns of the tibble. Note that the vectors must be of the same length, otherwise the tibble will be filled with NA values to make up the difference.\n\n# Create a tibble\nfood_tb <- tibble::tibble(\n    food_names = c(\n        \"Rice\",\n        \"Maize\",\n        \"Beans\",\n        \"Cassava\",\n        \"Potatoes\",\n        \"Maize\",\n        \"Wheat\"\n    ),\n    consumption = c(0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.01),\n    is_staple = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE)\n)\n\n# Print the tibble\nprint(food_tb)\n\n# A tibble: 7 × 3\n  food_names consumption is_staple\n  <chr>            <dbl> <lgl>    \n1 Rice              0.5  TRUE     \n2 Maize             0.4  TRUE     \n3 Beans             0.3  TRUE     \n4 Cassava           0.2  TRUE     \n5 Potatoes          0.1  FALSE    \n6 Maize             0.05 TRUE     \n7 Wheat             0.01 FALSE    \n\n\n\n\n\n\n\n\nExcercise\n\n\n\nUse the class() function to check the class of the food_df and food_tb objects. 1. What did you notice? 2. What is the difference between the two objects? Guess the data structure of each object. 3. Did you notice how the vector names were used as column names in the data frame and tibble?"
  },
  {
    "objectID": "data_structures.html#factors",
    "href": "data_structures.html#factors",
    "title": "3  Data Structures",
    "section": "3.3 Factors",
    "text": "3.3 Factors\nNote that a factor is actually a vector, but with an associated list of levels, always presented in alpha-numeric order. These are used by R functions such as lm() which does linear modelling, such as the analysis of variance. We shall see how factors can be used in the later section on data frames.\nLet us create a factor from a vector of character values. We can do this using the factor() function. The first argument is the vector of character values, and the second is the list of levels. If we don’t specify the levels, R will use the unique values in the vector, in alphabetical order.\n\n3.3.1 Coercing a vector to a factor\nExample of converting the food_names vector to a factor:\n\n# Create a factor without providing the levels argument\nfood_names_factor_1 <- factor(food_names)\n# Print the factor\nprint(food_names_factor_1)\n\n[1] Rice           Maize          Beans          Cassava        Potatoes      \n[6] Sweet potatoes Wheat         \nLevels: Beans Cassava Maize Potatoes Rice Sweet potatoes Wheat\n\n# Create a factor from a vector of character values\nfood_names_factor_2 <-\n    factor(\n        food_names,\n        levels = c(\n            \"Rice\",\n            \"Maize\",\n            \"Beans\",\n            \"Cassava\",\n            \"Potatoes\",\n            \"Sweet potatoes\",\n            \"Wheat\"\n        )\n    )\n\n# Print the factor\nprint(food_names_factor_2)\n\n[1] Rice           Maize          Beans          Cassava        Potatoes      \n[6] Sweet potatoes Wheat         \nLevels: Rice Maize Beans Cassava Potatoes Sweet potatoes Wheat\n\n\n\n\n\n\n\n\nExcercise\n\n\n\n\nWhat is the difference between the two factors?\nCreate a factor from the is_staple vector. What are the levels?\nCreate a factor from the consumption vector. What are the levels?\n\n\n\n\n\n3.3.2 Coercing a vector to a factor in a data frame\nExample of converting the food_names vector to a factor in a data frame:\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Use the food_tb data frame created above and convert the food_names column to a factor\nfood_tb <- mutate(food_tb, food_names = factor(food_names))\n\n# Print the data frame\nprint(food_tb)\n\n# A tibble: 7 × 3\n  food_names consumption is_staple\n  <fct>            <dbl> <lgl>    \n1 Rice              0.5  TRUE     \n2 Maize             0.4  TRUE     \n3 Beans             0.3  TRUE     \n4 Cassava           0.2  TRUE     \n5 Potatoes          0.1  FALSE    \n6 Maize             0.05 TRUE     \n7 Wheat             0.01 FALSE"
  },
  {
    "objectID": "data_structures.html#summary",
    "href": "data_structures.html#summary",
    "title": "3  Data Structures",
    "section": "3.4 Summary",
    "text": "3.4 Summary\nThere are other data structures in R, e.g. Matrix and lists but these are the most common. We will now look at some of the operations we can perform on vectors and data frames in the future sections.\nBut first,we introduced the dplyr package above. This is a package which provides a set of functions for manipulating data frames. We will use it extensively in this book. We can use the mutate() function to add a new column to a data frame. In this case we are adding a new column called food_names which is a factor version of the food_names column in the data frame.This means we introduced a new function mutate() and a new package dplyr.\nIn the next section we define what are packages and functions."
  },
  {
    "objectID": "packages_and_functions.html#functions",
    "href": "packages_and_functions.html#functions",
    "title": "4  Packages and Functions",
    "section": "4.1 Functions",
    "text": "4.1 Functions\nFunctions are a set of instructions that can be called by name. They are useful for automating repetitive tasks and for encapsulating complex tasks. Functions are defined using the function() function. An example of a function is the dataframe function which we used above to create a dataframe. A function takes in one or more arguments and returns a value. The arguments are specified in the function definition and the value is returned using the return() function. To see the arguments of a function, use the ? before the function name e.g. ?dataframe. To see the code of a function, just type the function name without the parentheses. For example, to see the code of the dataframe function, type dataframe without the parentheses. Other examples are head , str and summary functions.\n\n4.1.1 Creating a function\nThe basic syntax for defining a function is as follows:\n\n# Define a function\nfunction_name &lt;- function(arg1, arg2, ...) {\n    # Function body\n    # ...\n    # Return value\n    return(return_value)\n}\n\nFor example, let us create a function called add that takes in two arguments and returns the sum of the two arguments.\n\n# Define a function\nadd &lt;- function(x, y) {\n    # Return the sum of the two arguments\n    return(x + y)\n}\n\n# Call the function\nadd(2, 3)\n\n[1] 5"
  },
  {
    "objectID": "packages_and_functions.html#packages",
    "href": "packages_and_functions.html#packages",
    "title": "4  Packages and Functions",
    "section": "4.2 Packages",
    "text": "4.2 Packages\nA package is a collection of functions, data, and documentation that extends the functionality of R. There are thousands of packages available for R. To use a package, you first need to install it using the install.packages() function. Once installed, you can load the package using the library() function. For example, to install the dplyr package, you would type install.packages(\"dplyr\"). To load the dplyr package, you would type library(dplyr). To see the functions in a package, type help(package = \"package_name\") e.g. help(package = \"dplyr\"). To see the code of a function in a package, type package_name::function_name e.g. dplyr::mutate. You can also use the ? before the function name e.g. ?dplyr::mutate.\n\n4.2.1 Package sources\nThere are three main sources of packages for R: - CRAN - The Comprehensive R Archive Network: https://cran.r-project.org/. This is the main source of packages for R. It contains over 15,000 packages. To install a package from CRAN, you can use the install.packages() function. - GitHub: Most developers store their packages on GitHub. To install a package from GitHub, you can use the install_github() function from the devtools package. e.g. devtools::install_github(\"dzvoti/hcesNutR\"). Notice how i used package_name::function_name to call the install_github() function.\n\n\n4.2.2 Loading packages\nOnce installed a package need to be ‘loaded’ for its function to be available in R. This is done using the library() function. For example, to load the dplyr package, you would type library(dplyr). Alternatively you can use the require() function. For example, to load the dplyr package, you would type require(dplyr). The difference between the two functions is that library() will throw an error if the package is not installed, while require() will throw a warning. You can also use the :: operator to call a function from a package without loading the package. For example, to call the mutate() function from the dplyr package without loading the package, you would type dplyr::mutate(). This is useful when you want to use a function from a package without loading the package.\n\n\n4.2.3 Removing packages\nTo remove a package, you can use the remove.packages() function. For example, to remove the dplyr package, you would type remove.packages(\"dplyr\").\n\n\n4.2.4 Updating packages\nTo update a package, you can use the update.packages() function. For example, to update the dplyr package, you would type update.packages(\"dplyr\").\n\n\n4.2.5 Listing installed packages\nTo list all installed packages, you can use the installed.packages() function. For example, to list all installed packages, you would type installed.packages().\n\n\n4.2.6 Recomended packages\nThere are thousands of packages available for R. However, there are some packages that are recommended for beginners. These include: | Package | Description | | — | — | | tidyverse | A collection of packages designed for data science. It includes the dplyr, ggplot2, tidyr, readr, purrr, tibble, stringr, forcats and haven packages. | |here| A package for managing file paths.|\nNow that we know what packages and functions are, let us look at some of the functions we can use to manipulate vectors and dataframes in the next section on Data Import,Wrangling and Export."
  },
  {
    "objectID": "data_wrangling_and_io.html#data-inputimport",
    "href": "data_wrangling_and_io.html#data-inputimport",
    "title": "5  Data I/O and Wrangling",
    "section": "5.1 Data Input/Import",
    "text": "5.1 Data Input/Import\nThere are many ways to import data into R. In this section we will look at how to import data from a CSV file, an Excel file and Stata file. In the sample data folder there are *.csv files and stata files *.dta. Foe example to import the health data from a survey stored in hh_mod_a_filt_vMAPS.dta stored in the mwi-ihs5-sample-data folder within our working directory we run:\n\n# Load the haven package\nlibrary(haven)\n\n# Import roster data\nihs5_roster <- read_dta(here::here(\"mwi-ihs5-sample-data\", \"hh_mod_a_filt_vMAPS.dta\"))\n\n# Preview the data\nhead(ihs5_roster )\n\n# A tibble: 6 × 3\n  case_id      HHID                             region\n  <chr>        <chr>                             <dbl>\n1 201011000001 ee2d2915a43d589af42a8b88c279698d      3\n2 201011000002 23d0a64bef9c68896ab464af581c47be      1\n3 201011000003 c108a854e8e9bef3d5a7556ef051013c      3\n4 201011000004 45e28358fd8627fdbe8ddf2dcf62659e      1\n5 201011000005 4472919b195eb3d0dd527d2de706a6ce      1\n6 201011000006 695def6a945f7f46a3bdbc28659861fc      3\n\n\nTo read a csv file we use the read_csv() function from the readr package. For example, to import the IHS5_UNIT_CONVERSION_FACTORS_vMAPS.csv file stored in the mwi-ihs5-sample-data folder within our working directory we run:\n\n# Load the readr package\nlibrary(readr)\n\n# Import unit conversion factors data\nihs5_unit_conversion_factors <- read_csv(here::here(\"mwi-ihs5-sample-data\", \"IHS5_UNIT_CONVERSION_FACTORS_vMAPS.csv\"))\n\nRows: 2391 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): food_item_name, unit_code, unit_name, measure_id\ndbl (3): region, food_item_code, factor\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Preview the data\nhead(ihs5_unit_conversion_factors)\n\n# A tibble: 6 × 7\n  region food_item_name     food_item_code unit_code unit_name measure_id factor\n   <dbl> <chr>                       <dbl> <chr>     <chr>     <chr>       <dbl>\n1      1 MAIZE UFA MGAIWA …            101 97        BASIN     1-97-101    3.40 \n2      2 MAIZE UFA MGAIWA …            101 97        BASIN     2-97-101    3.40 \n3      3 MAIZE UFA MGAIWA …            101 97        BASIN     3-97-101    3.40 \n4      3 MAIZE UFA MGAIWA …            101 84        CUP       3-84-101    0.445\n5      3 MAIZE UFA MGAIWA …            101 82        3LITRE B… 3-82-101    2.33 \n6      1 MAIZE UFA MGAIWA …            101 25        TINA      1-25-101    0.323\n\n\n\n\n\n\n\n\nExcercise\n\n\n\n\nImport your own excel file into R.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNotice how all import operations are done within the here::here() function. This is because we are using the here package to manage file paths. The here::here() function returns the path to the file relative to the working directory. This is useful when you want to share your code with others, as they can run the code without having to change the file paths.\nIt is very import that file names and directories are typed as they are. R is sensitive to capital letters and spaces. For example, if you type IHS5_UNIT_CONVERSION_FACTORS_VMAPS.csv instead of IHS5_UNIT_CONVERSION_FACTORS_vMAPS.csv, R will throw an error. To get around this in RStudio use the tab key to autocomplete file names and directories.\n\n\nAfter importing files they are usually stored in memory as dataframes/tibbles. We can check the class of an object using the class() function. For example, to check the class of the ihs5_roster object, we would type class(ihs5_roster). We can also check the structure of an object using the str() function. For example, to check the structure of the ihs5_roster object, we would type str(ihs5_roster). We want to make sure that the data is imported correctly before we start manipulating it."
  },
  {
    "objectID": "data_wrangling_and_io.html#data-wrangling",
    "href": "data_wrangling_and_io.html#data-wrangling",
    "title": "5  Data I/O and Wrangling",
    "section": "5.2 Data Wrangling",
    "text": "5.2 Data Wrangling\nThe dplyr package from the tidyverse package is our data wrangling tool of choice. It provides a set of functions for manipulating dataframes e.g. renaming columns, conditional removal of rows, creation of other columns and so on. We will load and manipulate the consumption module of our hypothetical Malawi IHS5 survey data. The data is stored in the mwi-ihs5-sample-data folder within our working directory and is called HH_MOD_G1_vMAPS.dta. We will use the here package to manage file paths.\n\nlibrary(dplyr) # data manipulation\nlibrary(haven) # data import\nlibrary(here) # file paths\n\n\n5.2.1 Import the data\n\n# Import the data\nihs5_consumption <- read_dta(here::here(\"mwi-ihs5-sample-data\", \"HH_MOD_G1_vMAPS.dta\"))\n\n\n\n\n\n\n\nExcercise\n\n\n\n\nCheck if the data improrted correctly\nCheck the structure of the data\nHow many observations and variables are there?\n\n\n\n\n\n5.2.2 Subsetting data\n\n\n5.2.3 Subsetting data frames\nThere are a number of functions that can be used to extract subsets of R objects in tidyverse syntax. The most important are the following from the dplyr package:\n\nfilter() allows you to select a subset of rows in a data frame.\nselect() allows you to select a subset of columns in a data frame.\narrange() allows you to reorder the rows of a data frame.\nmutate() allows you to create new columns from existing columns.\nsummarise() allows you to collapse many values down to a single summary.\npull() allows you to extract a single column from a data frame as a vector.\n\n\n\n5.2.4 Subsetting columns\nThis data that we loaded is a randomly generated immitation of the Malawi Intergrated Household Survey 2018-2019 described here. This data contains responses on total consumption as well as disaggregation of the sources of these foods.In this book we will process only the `total consumption.\nRemember we said that our data is loaded in memory? Seeing that the ihs5_consumption data contains columns we do not need let us subset it. The select function in dplyr is very useful for this. For example to keep only the columns with household identifiers and food names, units and quantity of consumption we keep the following columns in our data; “case_id”, “HHID”, “hh_g01”, “hh_g01_oth”, “hh_g02”, “hh_g03a”, “hh_g03b”, “hh_g03b_label”, “hh_g03b_oth”, “hh_g03c”, “hh_g03c_1”.\n\n# Subset the data\nihs5_consumption_subset <-\n    select(\n        ihs5_consumption,\n        case_id,\n        HHID,\n        hh_g01,\n        hh_g01_oth,\n        hh_g02,\n        hh_g03a,\n        hh_g03b,\n        hh_g03b_label,\n        hh_g03b_oth,\n        hh_g03c,\n        hh_g03c_1\n    )\n\nThe syntax for most tidyverse functions is function (data,columns). Notice that we stored the subsetting operation in a new object called ihs5_consumption_subset? This is generally frowned upon unless we intend to use the original dataset for separate operations. Storing the subset in a new object will use up more memory to store the 2 objects. We can overwrite the original object by typing:\n\nihs5_consumption <- select(\n    ihs5_consumption,\n    case_id,\n    HHID,\n    hh_g01,\n    hh_g01_oth,\n    hh_g02,\n    hh_g03a,\n    hh_g03b,\n    hh_g03b_label,\n    hh_g03b_oth,\n    hh_g03c,\n    hh_g03c_1\n)\n\nNext let us give the columns more meaningful names. We can do this using the rename function. For example, to rename the hh_g01 column to consumedYN and hh_g02 to food_item, we would type:\n\n# Rename the columns\nihs5_consumption <-\n    rename(ihs5_consumption,\n           consumedYN = hh_g01,\n           food_item = hh_g02)\n\nNotice how our operations only affect the specific columns we specify? This is because the select and rename functions are smart and intiutive.\n\n\n\n\n\n\nExcercise\n\n\n\n\nRename the remaining columns to: |old_name | new_name| |—|—| |hh_g01_oth | food_item_other| |hh_g03a | consumption_quantity| |hh_g03b | consumption_unit| |hh_g03b_label | consumption_unit_label| |hh_g03b_oth | consumption_unit_oth| |hh_g03c | consumption_subunit_1| |hh_g03c_1 |consumption_subunit_2|\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nSolution:\n\n# Reload the data to start from scratch\nihs5_consumption <-\n    read_dta(here::here(\"mwi-ihs5-sample-data\", \"HH_MOD_G1_vMAPS.dta\"))\n\n# Rename the columns\nihs5_consumption <-\n    rename(\n        ihs5_consumption,\n        consumedYN = hh_g01,\n        food_item = hh_g02,\n        food_item_other = hh_g01_oth,\n        consumption_quantity = hh_g03a,\n        consumption_unit = hh_g03b,\n        consumption_unit_label = hh_g03b_label,\n        consumption_unit_oth = hh_g03b_oth,\n        consumption_subunit_1 = hh_g03c,\n        consumption_subunit_2 = hh_g03c_1\n    )\n\n\n\n\n\n\n5.2.5 Subsetting rows\nWe can also subset rows using the filter function. For example, to keep only the rows where consumedYN is equal to 1, we would type:\n\n# Subset the data\nihs5_consumption <- filter(ihs5_consumption, consumedYN == 1)\n\nNotice how we are using the logical operator == to test each row whether the value of consumedYN is equal to 1? This is called a conditional statement as we discussed in the previous sections."
  },
  {
    "objectID": "data_wrangling_and_io.html#chaining-operations-using-the-pipe-operator",
    "href": "data_wrangling_and_io.html#chaining-operations-using-the-pipe-operator",
    "title": "5  Data I/O and Wrangling",
    "section": "5.3 Chaining operations using the pipe operator",
    "text": "5.3 Chaining operations using the pipe operator\nWe can chain operations using the pipe operator %>% or |>. This is useful when we want to perform multiple operations on a dataset. For example, to read, subset the data and rename the columns in one operation, we would type:\n\n# Read, subset and rename the data\nihs5_consumption <-\n    read_dta(here::here(\"mwi-ihs5-sample-data\", \"HH_MOD_G1_vMAPS.dta\")) |>\n    select(\n        case_id,\n        HHID,\n        hh_g01,\n        hh_g01_oth,\n        hh_g02,\n        hh_g03a,\n        hh_g03b,\n        hh_g03b_label,\n        hh_g03b_oth,\n        hh_g03c,\n        hh_g03c_1\n    ) %>%\n    rename(\n        consumedYN = hh_g01,\n        food_item = hh_g02,\n        food_item_other = hh_g01_oth,\n        consumption_quantity = hh_g03a,\n        consumption_unit = hh_g03b,\n        consumption_unit_label = hh_g03b_label,\n        consumption_unit_oth = hh_g03b_oth,\n        consumption_subunit_1 = hh_g03c,\n        consumption_subunit_2 = hh_g03c_1\n    )\n\nWe deliberately used both the pipe operators %>% and |> to show that they are the same. The %>% is the most popular of the tidyverse pipes from the magrittr package. Recent versions (circa 2020) intoduced the native R pipe |>. The pipe operator is useful when we want to perform multiple operations on a dataset without storing the intermediate results in memory. In the above example we only stored the final result in memory. This is useful when we are working with large datasets and want to save memory.\n\n\n\n\n\n\nWarning\n\n\n\nWhen chaining operations we do not need to specify the data argument in the subsequent functions. This is because the output of the previous function is passed to the next function. If we want to specify the data argument, we can use the . symbol. For example, to specify the data argument in the rename function, we would type:\n\n\n\n5.3.1 Change the data type of a column\nThe mutate function is used to create new columns from existing columns. It is also used to change the data type of a column. For example, to change the data type of the consumption_quantity column to numeric, we would type:\n\nihs5_consumption <- ihs5_consumption |>\n    mutate(food_item_code = as.character(food_item))\n\n\n\n5.3.2 Create a new column\nAs we mentioned earlier, the mutate function is used to create new columns from existing columns. For example, to create a new column with hh_members (randomly generated) we would type:\n\nihs5_consumption <- ihs5_consumption |>\n    mutate(hh_members = sample(1:10, nrow(ihs5_consumption), replace = TRUE))\n\nHere we are using the sample function to generate random numbers between 1 and 10. The nrow function returns the number of rows in the ihs5_consumption data. The replace = TRUE argument tells the sample function to sample with replacement. This means that the same number can be sampled more than once. If we want to sample without replacement we would type replace = FALSE.\nWe used the sample function a lot during the generation of the sample data used in this book. You can see more on this in the data generation section.\n\n\n5.3.3 Vectorised operations\nThe mutate function is also useful for vectorised operations. For example, to create a new column with the consumption per person we would type:\n\nihs5_consumption <- ihs5_consumption |>\n    mutate(consumption_per_person = consumption_quantity / hh_members)\n\n\n\n\n\n\n\nExcercise\n\n\n\nSuppose this data is from a 7 day recall survey. Create a new column with the consumption per person per day.\n\n\n\n\n5.3.4 Enriching data\nWe can enrich our data by joining different files using the join function. The most common joins are left_join, right_join, inner_join and full_join.\nThe left_join function joins two dataframes by keeping all the rows in the first dataframe and matching the rows in the second dataframe.\nMost joining operations in hces data analysis are left_join operations as we want to keep all the rows in the primary data we are processing and enrich it with matched rows in the other data. For example, to join the ihs5_consumption data with the ihs5_household_identifies contained in hh_mod_a_filt_vMAPS.dta data we would type:\n\n# Import the data\nihs5_household_identifiers <-\n    read_dta(here::here(\"mwi-ihs5-sample-data\", \"hh_mod_a_filt_vMAPS.dta\"))\n\n# Join the data\nihs5_consumption_j1 <- ihs5_consumption |>\n    left_join(ihs5_household_identifiers, by = \"HHID\")\n\nThe result is an enriched dataset with rows from the ihs5_household_identifiers data that match the HHID column in the ihs5_consumption data. The by argument tells the left_join function which column to use to match the rows. If the column names are the same in both dataframes, we do not need to specify the by argument. For example, to join the ihs5_consumption data with the ihs5_household_identifies contained in hh_mod_a_filt_vMAPS.dta data we would type:\n\n# Import the data\nihs5_household_identifiers <-\n    read_dta(here::here(\"mwi-ihs5-sample-data\", \"hh_mod_a_filt_vMAPS.dta\"))\n\n# Join the data\nihs5_consumption <- ihs5_consumption |>\n    left_join(ihs5_household_identifiers)\n\n\n\n\n\n\n\nExcercise\n\n\n\n\nCompare the results of the two joins.\nWhat is the difference?\n\n\n\n\n\n5.3.5 Grouping and Summarising Data\nWe can group data using the group_by function. Grouping data is useful when we want to summarise data. In dplyr the summaries are created from the groups in the data. For eample to summarise the consumption_per_person by food_item we would type:\n\n# Summarise the data\nihs5_consumption_summary <- ihs5_consumption |>\n    group_by(food_item) |>\n    summarise(consumption_per_person = mean(consumption_per_person, na.rm = TRUE))\n\nHere we are using the mean function to calculate the mean of the consumption_per_person column. The na.rm = TRUE argument tells the mean function to ignore missing values.\nWe can also compute multiple summaries at once. For example, to compute the mean and standard deviation of the consumption_per_person column we would type:\n\n# Summarise the data\nihs5_consumption_summary <- ihs5_consumption |>\n    group_by(food_item) |>\n    summarise(\n        consumption_per_person_mean = mean(consumption_per_person, na.rm = TRUE),\n        consumption_per_person_sd = sd(consumption_per_person, na.rm = TRUE)\n    )\n\nTo compute summaries across multiple groups we can use the group_by function with multiple arguments. For example, to compute the mean and standard deviation of the consumption_per_person column by food_item and region we would type:\n\n# Summarise the data\nihs5_consumption_summary <- ihs5_consumption |>\n    group_by(food_item, region) |>\n    summarise(\n        consumption_per_person_mean = mean(consumption_per_person, na.rm = TRUE),\n        consumption_per_person_sd = sd(consumption_per_person, na.rm = TRUE)\n    )\n\nIn the next section we will learn how to use plots to visualise our data. A basic example of a plot is a bar chart. For example we can visualise the consumption per person by food item using a bar chart. To do this we will use the ggplot2 package from the tidyverse package like so:\n\n# Load the ggplot2 package\nlibrary(ggplot2)\n\n#  Plot the data\nihs5_consumption |>\n    # Add plot aesthetics\n    ggplot(aes(x = region, y = consumption_per_person, group = region)) +\n    # Add plot type\n    geom_boxplot() \n\nHere we plotted a boxplot of the consumption_per_person by region.\n\n\n5.3.6 Data Output/Export\nWe can export data from R using the write_csv() function from the readr package. For example, to export the ihs5_consumption data to a csv file called ihs5_consumption.csv stored in our working directory we run:\n\n# Export the data\nwrite_csv(ihs5_consumption, here::here(\"ihs5_consumption.csv\"))\n\nWe recommend exporting files to csv as this allows interoperability between various software. If you prefer exporting your data to excel, you can use the write_xlsx() function from the writexl package. For example, to export the ihs5_consumption data to an excel file called ihs5_consumption.xlsx stored in our working directory we run:\n\n# Export the data\nwritexl::write_xlsx(ihs5_consumption, here::here(\"ihs5_consumption.xlsx\"))\n\nTo export the data to a stata file, we can use the write_dta() function from the haven package. For example, to export the ihs5_consumption data to a stata file called ihs5_consumption.dta stored in our working directory we run:\n\n# Export the data\nwrite_dta(ihs5_consumption, here::here(\"ihs5_consumption.dta\"))"
  },
  {
    "objectID": "hcesNutR-package.html",
    "href": "hcesNutR-package.html",
    "title": "7  hcesNutR Package",
    "section": "",
    "text": "8 Calculate AFE/AME and add to the data"
  },
  {
    "objectID": "hcesNutR-package.html#reporting-bugs",
    "href": "hcesNutR-package.html#reporting-bugs",
    "title": "7  hcesNutR Package",
    "section": "7.1 Reporting bugs",
    "text": "7.1 Reporting bugs\nPlease report any bugs or issues here."
  },
  {
    "objectID": "hcesNutR-package.html#installation",
    "href": "hcesNutR-package.html#installation",
    "title": "7  hcesNutR Package",
    "section": "7.2 Installation",
    "text": "7.2 Installation\nYou can install the development version of hcesNutR from GitHub with:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"dzvoti/hcesNutR\")\n\nAs we discussed in previous chapters you need to load the package in your R session before you can use it. You can load the package by running the following code in your R console.\n\nlibrary(hcesNutR)"
  },
  {
    "objectID": "hcesNutR-package.html#functions-in-the-package",
    "href": "hcesNutR-package.html#functions-in-the-package",
    "title": "7  hcesNutR Package",
    "section": "7.3 Functions in the package",
    "text": "7.3 Functions in the package\nYou can view the functions in the package by running the following code in your R console.\n\nls(\"package:hcesNutR\")"
  },
  {
    "objectID": "hcesNutR-package.html#example",
    "href": "hcesNutR-package.html#example",
    "title": "7  hcesNutR Package",
    "section": "7.4 Example",
    "text": "7.4 Example\nThis is a basic example which shows you the use of the functions in the package. The example uses the sample_hces.dta data that is included in the package. You can download the data by running hcesNutR::sample_hces() in your R console. The data is randomly generated to mimic the structure of the Fifth Integrated Household Survey 2019-2020 an HCES of Malawi. The variables and structure of this data is found here"
  },
  {
    "objectID": "hcesNutR-package.html#import-and-explore-the-sample-data",
    "href": "hcesNutR-package.html#import-and-explore-the-sample-data",
    "title": "7  hcesNutR Package",
    "section": "7.5 Import and explore the sample data",
    "text": "7.5 Import and explore the sample data\n\n# Import the data using the haven package from the tidyverse\nsample_hces <-\n  haven::read_dta(here::here(\"data\", \"mwi-ihs5-sample-data\", \"HH_MOD_G1_vMAPS.dta\"))\n\n\n# Preview first 5 rows\nsample_hces |>\nhead() |>\n  knitr::kable()\n\n\n7.5.1 Trim the data\nIn this example we will use hcesNutR functions to demonstrate processing of total consumption data. The total consumption data is the data that contains the total consumption of each food item by each household. The other consumption columns contain values for consumption from sources i.e. gifted, purchased, ownProduced. The workflow for processing these is the same as demonstrated below.\n\n# Trim the data to total consumption\nsample_hces <-\n  sample_hces |> \n  dplyr::select(case_id:HHID, hh_g01:hh_g03c_1)\n\n# Preview\nsample_hces |>\n  head(5) |>\n  knitr::kable()"
  },
  {
    "objectID": "hcesNutR-package.html#hcesnutr-workflow",
    "href": "hcesNutR-package.html#hcesnutr-workflow",
    "title": "7  hcesNutR Package",
    "section": "7.5 hcesnutR Workflow",
    "text": "7.5 hcesnutR Workflow\n\n7.5.1 Column Naming Conventions and Renaming\nThe sample_hces data is in stata format which contains data with short column name codes that have associated “question” labels that explain the contents of the data. To make the column names more interpretable, the package provides the rename_hces function, which can be used to rename the column codes to standard hces names used downstream.\nThe rename_hces function uses column names from the standard_name_mappings_pairs dataset within the package. Alternatively, a user can create their own name pairs or manually rename their columns to the standard names.\nIt is important to note that all downstream functions in the hcesNutR package work with standard names and will not work with the short column names. Therefore, it is recommended to use the rename_hces() function to ensure that the column names are consistent with the package’s naming conventions.\nFor more information on how to use the rename_hces function, please refer to the function’s documentation: rename_hces.\n\n# Rename the variables\nsample_hces &lt;- hcesNutR::rename_hces(sample_hces,\n                                     country_name = \"MWI\",\n                                     survey_name = \"IHS5\")\n\n\n\n7.5.2 Remove unconsumed food items\nHCES surveys administer a standard questionaire to each household where they are asked to conform whether they consumed the food items on their standard list. If a household did not consume a food item, the value of the ‘consYN’ is set to a constant. The remove_unconsumed function removes all food items that were not consumed by the household. The function takes in a data frame and the name of the column that contains the consumption information. The function also takes in the value that indicates that the food item was consumed.\n\n# Remove unconsumed food items\nsample_hces &lt;- hcesNutR::remove_unconsumed(sample_hces,\n                                           consCol = \"consYN\", \n                                           consVal = 1)\n\n\n\n7.5.3 Create two columns from each dbl+lbl column\nThe create_dta_labels function creates two columns from each dbl+lbl (double plus label) column. The first column contains the numeric values and the second column contains the labels. The function takes in a data frame and finds all columns that contains the double plus label column. The function returns a data frame with the new columns.\n\n# Split dbl+lbl columns\nsample_hces &lt;- hcesNutR::create_dta_labels(sample_hces)\n\n\n\n7.5.4 Concatenate columns\nSome HCES data surveys split consumed food items or their consumption units into multiple columns. The concatenate_columns function cleans the data by combining the split columns into one column. The function can exclude values from contatenation by specifying the whole or part of values to be excluded.\n\nConcatenate food item names\n\n# Merge food item names\nsample_hces &lt;-\n  hcesNutR::concatenate_columns(sample_hces,\n                                c(\"item_code_name\", \n                                  \"item_oth\"),\n                                \"SPECIFY\",\n                                \"item_code_name\")\n\n\n\nConcatenate food item units\n\n# Merge consumption unit names. For units it is essential to remove parentesis as they are the major cause of duplicate units\nsample_hces &lt;-\n  hcesNutR::concatenate_columns(\n    sample_hces,\n    c(\n      \"cons_unit_name\",\n      \"cons_unit_oth\",\n      \"cons_unit_size_name\",\n      \"hh_g03c_1_name\"\n    ),\n    \"SPECIFY\",\n    \"cons_unit_name\",\n    TRUE\n  )\n\n\n\n\n\n\n\nTip\n\n\n\nUse the select and rename functions from the dplyr package to subset the columns containing food item name , food item code, food unit name and food unit code. This is to ensure that the names are meaningful and consistent with the package’s naming conventions.\n\n\n\nsample_hces &lt;- sample_hces |&gt;\n  dplyr::select(\n    case_id,\n    hhid,\n    item_code_name,\n    item_code_code,\n    cons_unit_name,\n    cons_unitA,\n    cons_quant\n  ) |&gt;\n  dplyr::rename(food_name = item_code_name,\n                food_code = item_code_code,\n                cons_unit_code = cons_unitA)\n\n\n\n\n7.5.5 Match survey food items to standard food items\nThe match_food_names function is useful for standardising survey food names. This is feasible due to an internal dataset of standard food item names matched with their corresponding survey food names for supported surveys. Alternatively users can use their own food matching names by passing a csv to the function. See hcesNutR::food_list for csv structure.\n\nsample_hces &lt;-\n  match_food_names_v2(\n    sample_hces,\n    country = \"MWI\",\n    survey = \"IHS5\",\n    food_name_col = \"food_name\",\n    food_code_col = \"food_code\",\n    overwrite = FALSE\n  )\n\n\n\n7.5.6 Match survey consumption units to standard consumption units\nThe match_food_units_v2 function is useful for standardising survey consumption units. This is feasible due to an internal dataset of standard consumption units matched with their corresponding survey consumption units for supported surveys. Alternatively users can download our template from hcesNutR::unit_names_n_codes_df and modify it to use their own consumption unit matching names.\n\nsample_hces &lt;-\n  match_food_units_v2(\n    sample_hces,\n    country = \"MWI\",\n    survey = \"IHS5\",\n    unit_name_col = \"cons_unit_name\",\n    unit_code_col = \"cons_unit_code\",\n    matches_csv = NULL,\n    overwrite = FALSE\n  )\n\n\n\n7.5.7 Add regions and districts to the data\nIdentify the HCES module that contains household identifiers. In some cases this will already be present in the HCES data and should be skipped. From the household identifiers select the ones that are required and add to the data. In this example we will add the region and district identifiers to the data from the hh_mod_a_filt.dta file.\n\n# Import household identifiers from the hh_mod_a_filt.dta file\nhousehold_identifiers &lt;-\n  haven::read_dta(here::here(\"data\",\n                             \"mwi-ihs5-sample-data\",\n                             \"hh_mod_a_filt_vMAPS.dta\")) |&gt;\n  # subset the identifiers and keep only the ones needed.\n  dplyr::select(case_id,\n                HHID,\n                region) |&gt;\n  dplyr::rename(hhid = HHID)\n\n# Add the identifiers to the data\nsample_hces &lt;-\n  dplyr::left_join(sample_hces,\n                   household_identifiers,\n                   by = c(\"hhid\", \"case_id\"))\n\n\n\n7.5.8 Create a measure_id column\nThe create_measure_id function creates a measure id column that is used to identify the consumption measure of each food item. The function takes in a data frame and the name of the column that contains the consumption information. The function also takes in the value that indicates that the food item was consumed.\nThe measure_id is a unique identifier that allows us to join the consumption data with the food conversion factors data.\n\n# Create measure id column\nsample_hces &lt;-\n  create_measure_id(\n    sample_hces,\n    country = \"MWI\",\n    survey = \"IHS5\",\n    cols = c(\"region\",\n             \"matched_cons_unit_code\",\n             \"matched_food_code\"),\n    include_ISOs = FALSE\n  )\n\n\n\n7.5.9 Import food conversion factors.\nThe available data comes with a `food_conversion fcators file which has conversion fcators that link the food names and units to their corresponding\n\n# Import food conversion factors file\nIHS5_conv_fct &lt;-\n  readr::read_csv(\n    here::here(\n      \"data\",\n      \"mwi-ihs5-sample-data\",\n      \"IHS5_UNIT_CONVERSION_FACTORS_vMAPS.csv\"\n    )\n  )\n\nWe need to check if the conversion factors file contain all the expected conversion factors for the hces data being processed. The check_conv_fct function checks if the conversion factors file contains all the expected conversion factors for the hces data being processed. T\n\n\n\n\n\n\nWarning\n\n\n\nRemember this data was randomly generated so it is expected that the weights will not be realistic. Also not all food items have conversion factors so the weight of those food items will be NA.\n\n\n\n# Check conversion factors \ncheck_conv_fct(hces_df = sample_hces, \n               conv_fct_df = IHS5_conv_fct)\n\n\n\n7.5.10 Calculate weight of food items in kilograms.\nThe apply_wght_conv_fct function will take the hces_df and conv_fct_df and calculate the weight of each food item in kilograms.\n\n\n\n\n\n\nWarning\n\n\n\nRemember this data was randomly generated so it is expected that the weights will not be realistic. Also not all food items have conversion factors so the weight of those food items will be NA.\n\n\n\nsample_hces &lt;-\n  apply_wght_conv_fct(\n    hces_df = sample_hces,\n    conv_fct_df = IHS5_conv_fct,\n    factor_col = \"factor\",\n    measure_id_col = \"measure_id\",\n    wt_kg_col = \"wt_kg\",\n    cons_qnty_col = \"cons_quant\",\n    allowDuplicates = TRUE\n  )\n\n\n\n7.5.11 Calculate AFE/AME and add to the data\n\n\n\n\n\n\nAssumptions\n\n\n\nThe ame/afe factors are calculated using the following assumptions: - Merge HH demographic data with AME/AFE factors - Men’s weight: 65kg (assumption) - Women’s weight: 55kg (from DHS) - PAL: 1.6X the BMR\n\n\n\nImport data required\nIn order to calculate the AFE and AME metrics we require the following data: - Household roster with the sex and age of each individual HH_MOD_B_vMAPS.dta - Household health HH_MOD_D_vMAPS.dta - AFE and AME factors IHS5_AME_FACTORS_vMAPS.csv and IHS5_AME_SPEC_vMAPS.csv\n\n# Import data of the roster and health modules of the IHS5 survey\nihs5_roster &lt;-\n  haven::read_dta(here::here(\"data\",\n                             \"mwi-ihs5-sample-data\",\n                             \"HH_MOD_B_vMAPS.dta\"))\nihs5_health &lt;-\n  haven::read_dta(here::here(\"data\",\n                             \"mwi-ihs5-sample-data\",\n                             \"HH_MOD_D_vMAPS.dta\"))\n\n# Import data of the AME/AFE factors and specifications\name_factors &lt;-\n  read.csv(here::here(\"data\",\n                      \"mwi-ihs5-sample-data\",\n                      \"IHS5_AME_FACTORS_vMAPS.csv\")) |&gt;\n  janitor::clean_names()\n\name_spec_factors &lt;-\n  read.csv(here::here(\"data\",\n                      \"mwi-ihs5-sample-data\",\n                      \"IHS5_AME_SPEC_vMAPS.csv\")) |&gt;\n  janitor::clean_names() |&gt;\n  # Rename the population column to cat and select the relevant columns\n  dplyr::rename(cat = population) |&gt;\n  dplyr::select(cat, ame_spec, afe_spec)\n\n\n\nExtra energy requirements for pregnancy\n\n# Extra energy requirements for pregnancy and Illness\npregnantPersons &lt;- ihs5_health |&gt;\n  dplyr::filter(hh_d05a == 28 |\n                  hh_d05b == 28) |&gt; \n  # NOTE: 28 is the code for pregnancy in this survey\n  dplyr::mutate(ame_preg = 0.11, afe_preg = 0.14) |&gt; \n  dplyr::select(HHID, ame_preg, afe_preg)\n\n\n\nProcess HH roster data\n\n# Process the roster data and rename variables to be more intuitive\naMFe_summaries &lt;- ihs5_roster |&gt;\n  # Rename the variables to be more intuitive\n  dplyr::rename(sex = hh_b03, age_y = hh_b05a, age_m = hh_b05b) |&gt;\n  dplyr::mutate(age_m_total = (age_y * 12 + age_m)) |&gt; \n  # Add the AME/AFE factors to the roster data\n  dplyr::left_join(ame_factors, by = c(\"age_y\" = \"age\")) |&gt; \n  dplyr::mutate(\n    ame_base = dplyr::case_when(sex == 1 ~ ame_m, sex == 2 ~ ame_f),\n    afe_base = dplyr::case_when(sex == 1 ~ afe_m, sex == 2 ~ afe_f),\n    age_u1_cat = dplyr::case_when(\n      # NOTE: Round here will ensure that decimals are not omited in the calculation.\n      round(age_m_total) %in% 0:5 ~ \"0-5 months\",\n      round(age_m_total) %in% 6:8 ~ \"6-8 months\",\n      round(age_m_total) %in% 9:11 ~ \"9-11 months\"\n    )\n  ) |&gt;\n  # Add the AME/AFE factors for the specific age categories\n  dplyr::left_join(ame_spec_factors, by = c(\"age_u1_cat\" = \"cat\")) |&gt;\n  # Dietary requirements for children under 1 year old\n  dplyr::mutate(\n    ame_lac = dplyr::case_when(age_y &lt; 2 ~ 0.19),\n    afe_lac = dplyr::case_when(age_y &lt; 2 ~ 0.24)\n  ) |&gt;\n  dplyr::rowwise() |&gt;\n  # TODO: Will it not be better to have the pregnancy values added at the same time here?\n  dplyr::mutate(ame = sum(c(ame_base, ame_spec, ame_lac), na.rm = TRUE),\n                afe = sum(c(afe_base, afe_spec, afe_lac), na.rm = TRUE)) |&gt;\n  # Calculate number of individuals in the households\n  dplyr::group_by(HHID) |&gt;\n  dplyr::summarize(\n    hh_persons = dplyr::n(),\n    hh_ame = sum(ame),\n    hh_afe = sum(afe)\n  ) |&gt;\n  # Merge with the pregnancy and illness data\n  dplyr::left_join(pregnantPersons, by = \"HHID\") |&gt;\n  dplyr::rowwise() |&gt;\n  dplyr::mutate(hh_ame = sum(c(hh_ame, ame_preg), na.rm = T),\n                hh_afe = sum(c(hh_afe, afe_preg), na.rm = T)) |&gt;\n  dplyr::ungroup() |&gt;\n  # Fix single household factors\n  dplyr::mutate(\n    hh_ame = dplyr::if_else(hh_persons == 1, 1, hh_ame),\n    hh_afe = dplyr::if_else(hh_persons == 1, 1, hh_afe)\n  ) |&gt;\n  dplyr::select(HHID, hh_persons, hh_ame, hh_afe) |&gt;\n  dplyr::rename(hhid = HHID)\n\n\n\nEnrich Consumption Data with AFE/AME\nWe will use the left_join function from dplyr to join the consumption data with the aMFe_summaries data. The left_join function will join the aMFe_summaries data to the sample_hces data by matching the hhid column in both data sets. The left_join function will add the hh_persons, hh_ame and hh_afe columns to the sample_hces data. The hh_persons column contains the number of people in each household. The hh_ame and hh_afe columns contain the AME and AFE factors for each household.\n\nsample_hces &lt;- sample_hces |&gt; \n  dplyr::left_join(aMFe_summaries)\n\nNow we have a “clean” data set that we can use for analysis."
  },
  {
    "objectID": "hcesNutR-package.html#assumptions",
    "href": "hcesNutR-package.html#assumptions",
    "title": "7  hcesNutR Package",
    "section": "8.1 Assumptions",
    "text": "8.1 Assumptions\nMerge HH demographic data with AME/AFE factors Men’s weight: 65kg (assumption) Women’s weight: 55kg (from DHS) PAL: 1.6X the BMR"
  },
  {
    "objectID": "hcesNutR-package.html#import-data-required",
    "href": "hcesNutR-package.html#import-data-required",
    "title": "7  hcesNutR Package",
    "section": "8.2 Import data required",
    "text": "8.2 Import data required\nIn order to calculate the AFE and AME metrics we require the following data: - Household roster with the sex and age of each individual - Household health - AFE and AME factors\n\n# Import data of the roster and health modules of the IHS5 survey\nihs5_roster <-\n  haven::read_dta(here::here(\"data\", \"mwi-ihs5-sample-data\", \"HH_MOD_B_vMAPS.dta\"))\nihs5_health <-\n  haven::read_dta(here::here(\"data\", \"mwi-ihs5-sample-data\", \"HH_MOD_D_vMAPS.dta\"))\n\n# Import data of the AME/AFE factors and specifications\name_factors <-\n  read.csv(here::here(\n    \"data\",\n    \"mwi-ihs5-sample-data\",\n    \"IHS5_AME_FACTORS_vMAPS.csv\"\n  )) |>\n  janitor::clean_names()\n\name_spec_factors <-\n  read.csv(here::here(\"data\", \"mwi-ihs5-sample-data\", \"IHS5_AME_SPEC_vMAPS.csv\")) |>\n  janitor::clean_names() |>\n  # Rename the population column to cat and select the relevant columns\n  dplyr::rename(cat = population) |>\n  dplyr::select(cat, ame_spec, afe_spec)"
  },
  {
    "objectID": "hcesNutR-package.html#extra-energy-requirements-for-pregnancy",
    "href": "hcesNutR-package.html#extra-energy-requirements-for-pregnancy",
    "title": "7  hcesNutR Package",
    "section": "8.3 Extra energy requirements for pregnancy",
    "text": "8.3 Extra energy requirements for pregnancy\n\n# # Extra energy requirements for pregnancy and Illness\npregnantPersons <- ihs5_health |>\n    dplyr::filter(hh_d05a == 28 | hh_d05b == 28) |> # NOTE: 28 is the code for pregnancy in this survey\n    dplyr::mutate(ame_preg = 0.11, afe_preg = 0.14) |> # NOTE: where do these values come from, DHS?\n    dplyr::select(HHID, ame_preg, afe_preg)\n\n# Preview\npregnantPersons |>\n    head() |>\n    DT::datatable()"
  },
  {
    "objectID": "fct_standardisation.html",
    "href": "fct_standardisation.html",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "",
    "text": "9 Environment Prep\nFirst we need to check what packages are installed. If you have run this template before in this RStudio project and are sure these packages are already installed, you can comment out (put a hash at the start of) line 20, and skip it."
  },
  {
    "objectID": "fct_standardisation.html#objective",
    "href": "fct_standardisation.html#objective",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "8.1 Objective",
    "text": "8.1 Objective\nThis document provide, together with the template document, the steps and description for cleaning and standardising FCTs from diverse sources. More details about the cleaned data that can be found in the repository is documented in this folder (documentation).\nFor easy navigation and use of this script it is recommended to use Rstudio. In RStudio please click the “Show Document Outline” button to the right of the source button, at the top right of this window. This will allow for easier navigation of the script."
  },
  {
    "objectID": "fct_standardisation.html#food-composition-functions",
    "href": "fct_standardisation.html#food-composition-functions",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "9.1 Food composition functions",
    "text": "9.1 Food composition functions\n\n# We also need to import some custom functions in another script:\nsource(here::here(\"functions.R\")) # Loading nutrition functions"
  },
  {
    "objectID": "fct_standardisation.html#data-license-check",
    "href": "fct_standardisation.html#data-license-check",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "10.1 Data License Check",
    "text": "10.1 Data License Check\nBefore using any dataset, we recommend to check licensing conditions & record the data source, you can use the README template."
  },
  {
    "objectID": "fct_standardisation.html#data-download",
    "href": "fct_standardisation.html#data-download",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "10.2 Data Download",
    "text": "10.2 Data Download\nIf the data is publicly available online, usually you only need to run the code below to obtain the raw files. Remember you only need to do it the first time! Then, the data will be stored in the folder of your choice (see below).\nFor instance, many raw files can be found provided by the FAO here, in various formats - https://www.fao.org/infoods/infoods/tables-and-databases/en/\nOnce the link to the data is found, check what file type it is, and paste the direct file link to replace the fill-in value below.\nPlease note: in the chunck of code below, the ‘template’ is a fill in value for a folder - if you wish to store this file in a folder, you must create a folder in your here::here location (found by running here::here()) and replace ‘template’ with that folders name. It is also important to make sure that the filename you pick for the downloaded file has the same file suffix (e.g. ‘.xlsx’) as the file you are downloading.\n\nf <- \"http://www.the-source-of-the-data/.../the-file-data.xlsx\"\n\ndownload.file(f,  # the location where is downloaded from \n   destfile = here::here('template', \"the-file-name-of-data.xlsx\"), # the location where you                                                 wish the file to be stored in your computer. \n            method=\"wininet\", # use \"curl\" for OS X / Linux, \"wininet\" for Windows \n            mode=\"wb\")"
  },
  {
    "objectID": "fct_standardisation.html#file-names-conventions",
    "href": "fct_standardisation.html#file-names-conventions",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "10.3 File names conventions",
    "text": "10.3 File names conventions\nWe advise to use the ISO code (2 digits) (see ISO 3166 2-alpha code for further information) of the country or the region of the FCT scope, plus the two last digits of the year of publication to name, both the folder which will contain the data and the scripts related to the FCT. For instance, Kenya FCT, 2018 will be coded as KE18. This will help with the interoperability, reusability and findability of the data. Also, to streamline the work in the future. That name convention will be used also as the identifier of the FCT. See section X.x. Variable re-naming."
  },
  {
    "objectID": "fct_standardisation.html#identifying-the-file",
    "href": "fct_standardisation.html#identifying-the-file",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "11.1 Identifying the file",
    "text": "11.1 Identifying the file\n\n11.1.1 Using the download code above (1.2.)\nFirst, we must find the file on your system that we want to import. If using RStudio: If you used the download method above Section 1.2 then we will see the same location as specified there to specify the file. Simply copy the contents of the here::here brackets and use it to fill the here::here brackets in the line of code below.\n\n#This identifies the file and file path, and saves it as a variable\nFCT_file_location <- here::here('template', \"the-file-name-of-data.xlsx\") \n\n\n\n11.1.2 Using here::here()\n\nA brief introduction to here::here()\nIf you are using an RStudio project but used a different download method, or already have the file you want to process on your computer, or are using base R we can still use the here::here function, however we will have to find the file first. Best practise is to put the file in the same folder as this script, or in a folder within the project. If this is done, then use here::here() to find your current working directory, and then navigate to the file folder.\n\n# Run this script to see where is your directory\nhere::here()\n\nIn order to navigate there, I have to include each subfolder between my here::here location and the file itself (so the ‘Research’ folder, the ‘FCT_cleaning’ folder and the ‘FCT_1’ folder). To do this, specify these folders in here::here, and then specify the file itself, like so: here::here('Research', 'FCT_cleaning', 'FCT_1', 'The_actual_fct.xlsx'). If using an RStudio project, and you put this .R file and the data file in the same folder as the RStudio project or within a subfolder, this is much easier as your project/here::here location automatically moves to the main project folder. More information about the here package can be found here.\n\n\nUsing here::here()\nFind your file in your computer, and then direct here::here to it - e.g.: (edit the line below to match your file location, remove hash from the start of the line below and run)\n\nFCT_file_location <- here::here('Research', 'FCT_cleaning', 'FCT_1', 'The_actual_fct.xlsx') #This identifies the file and file path, and saves it as a variable"
  },
  {
    "objectID": "fct_standardisation.html#importing-files",
    "href": "fct_standardisation.html#importing-files",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "11.2 Importing Files",
    "text": "11.2 Importing Files\nDuring import, a identifier for the FCT is created and added to the table. Please replace ‘MW19’ from the next code chunck with the FCT id., comprised of the countries ISO 3166 2-alpha code, and the year the FCT was produced (e.g. for the Malawi FCT from 2019, the reference would be ‘MW19’). This should be the same as the folder name explained in (section 1.3)[link-to-section].\n\n# This is an example of the name \nFCT_id <- 'MW19' # Change two first letter for your ISO 2 code & the two digits for the last two digits of the year of publication.\n\nFCT files come in many different forms - the most common being “.xlsx” files and “.csv” files. Methods to import both of these file types will be covered - please navigate to the relevant subsection.\n\n11.2.1 Importing .xlsx files\nFor the excel-type of files, first, you need to check what information is provided and which of the sheet is providing the FC data.\n\ndata.df <- readxl::read_excel(FCT_file_location, #The file location, as                            identified in section 2.1\n                              sheet = 1  # Change to the excel sheet where                              the FCT is stored in the excel file\n                              ) %>%  \n  mutate(source_fct = FCT_ref)  #Creates the source_fct column and fills with                 a id for this FCT, as filled in in section 2.2. \n\n\n\n11.2.2 Importing .csv files\n\ndata.df <- read.csv2(FCT_file_location, #The file location, as identified in section 2.1\n                     sep = \",\") %>%  # Replace w/ other symbol if needed\n  mutate(source_fct = FCT_ref) #Creates the source_fct column and fills with a id for this FCT, as filled in in section 2.2. \n\nOnce imported, it is important to check the data.frame created from the csv, by using head(data.df) or clicking on its entry in the Environment panel of RStudio (This second option is not advised with very large files, however, as it can be slow).\nIf the data shown by doing this has all its columns combined, with a symbol in-between, then that symbol (e.g. ‘;’) is the separator for that csv. Replace comma in the sep = \",\" line from the code block above with the # new symbol, and run the entire block again.\n\n# Checking the dataframe\nhead(data.df)"
  },
  {
    "objectID": "fct_standardisation.html#checking-the-loaded-data",
    "href": "fct_standardisation.html#checking-the-loaded-data",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "11.3 Checking the loaded data",
    "text": "11.3 Checking the loaded data"
  },
  {
    "objectID": "fct_standardisation.html#how-many-rows-columns-have-the-data",
    "href": "fct_standardisation.html#how-many-rows-columns-have-the-data",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "11.4 How many rows & columns have the data?",
    "text": "11.4 How many rows & columns have the data?\n\ndim(data.df) # rows & columns"
  },
  {
    "objectID": "fct_standardisation.html#what-are-the-variables-names",
    "href": "fct_standardisation.html#what-are-the-variables-names",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "11.5 What are the variables names?",
    "text": "11.5 What are the variables names?\n\nnames(data.df)\n\nIf we are happy that we have loaded the correct FCT file, then proceed. If not, find the correct file and import it instead."
  },
  {
    "objectID": "fct_standardisation.html#visually-checking-the-data",
    "href": "fct_standardisation.html#visually-checking-the-data",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "12.1 Visually checking the data",
    "text": "12.1 Visually checking the data\n\n# Checking the first rows and columns\nhead(data.df) \n\n# Checking the last rows and columns\ntail(data.df)\n\n# Opening the dataframe in a tab, \n#Note: if the dataset is very very big, may crash the R session.\nView(data.df)"
  },
  {
    "objectID": "fct_standardisation.html#trimming-dataframe-rows",
    "href": "fct_standardisation.html#trimming-dataframe-rows",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "12.2 Trimming dataframe rows",
    "text": "12.2 Trimming dataframe rows\nRunning this will trim down the table to only include the row numbers between x and y - replace x and y with your desired values. If you wanted to include multiple row ranges, that is also possible - use comments to differentiate between different row ranges and individual rows. e.g. if you wanted to include rows a:b, row c, row e, and rows g:x, then the code would be slice(a:b, c, e, g:x).\n\ndata.df <- data.df %>% slice(x:y)"
  },
  {
    "objectID": "hcesNutR-package.html#sample-data",
    "href": "hcesNutR-package.html#sample-data",
    "title": "7  hcesNutR Package",
    "section": "7.4 Sample data",
    "text": "7.4 Sample data\nThis is a basic example which shows you the use of the functions in the package. The data is randomly generated to mimic the structure of the Fifth Integrated Household Survey 2019-2020 an HCES of Malawi. The variables and structure of this data is found here\n\n\n\n\n\n\nTip\n\n\n\nAll functions in this package take a dataframe/tibble as input data. This is by design to allow flexibility on input data. The example used here is for use on stata files with .dta but the functions should work with .csv files as well.\n\n\n\n7.4.1 Import and explore the sample data\nImport the sample data from the r4hces-data/mwi-ihs5-sample-data folder. Use the read_dta function from the haven package to import it.\n\n# Import the data using the haven package from the tidyverse\nsample_hces &lt;-\n  haven::read_dta(here::here(\"data\", \n                             \"mwi-ihs5-sample-data\",\n                             \"HH_MOD_G1_vMAPS.dta\"))\n\n\n\n7.4.2 Trim the data\nIn this example we will use hcesNutR functions to demonstrate processing of total consumption data. The total consumption data is the data that contains the total consumption of each food item by each household. The other consumption columns contain values for consumption from sources i.e. gifted, purchased, ownProduced. The workflow for processing the “other” consumption data is the same as demonstrated below.\n\n# Trim the data to total consumption\nsample_hces &lt;- sample_hces |&gt;\n  dplyr::select(case_id:HHID,\n                hh_g01:hh_g03c_1)"
  },
  {
    "objectID": "hcesNutR-package.html#summary",
    "href": "hcesNutR-package.html#summary",
    "title": "7  hcesNutR Package",
    "section": "7.6 Summary",
    "text": "7.6 Summary\nThis chapter demonstrated the use of the hcesNutR package to process HCES data. The package contains functions that will help with the analysis of HCES data. The package also contains the sample data used in this book i.e. r4hces-data/mwi-ihs5-sample-data We used this sample data to demonstrate the use of the functions in the package. The package is still under development and will be updated regularly.Please report any bugs or issues here."
  },
  {
    "objectID": "hcesNutR-package.html#future-work",
    "href": "hcesNutR-package.html#future-work",
    "title": "7  hcesNutR Package",
    "section": "7.7 Future work",
    "text": "7.7 Future work\n\nAdd more functions to the package\nSupport more surveys (NGA Living Standards Survey 2018-2019)"
  }
]