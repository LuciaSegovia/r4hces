[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Household Consumption and Expenditure Surveys",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "index.html#about-this-manual",
    "href": "index.html#about-this-manual",
    "title": "R for Household Consumption and Expenditure Surveys",
    "section": "About this manual",
    "text": "About this manual\nThis manual is designed for absolute beginners who are interested in using R and RStudio for nutrition analysis of household consumption and expenditure surveys(HCES). The manual is an adaptation of materials for statistical analysis of HCES developed by the Micronutrient Action Policy Support(MAPS) Project and made available to all for use, without warranty or liability. The MAPS project is funded by the Bill and Melinda Gates Foundation."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "R for Household Consumption and Expenditure Surveys",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe would like to thank the following people for their contributions to this manual:\nLiberty Mlambo, Lucia Sergovia de la Revilla, Thomas Codd,Gareth Osman, Kevin Tang, Tineka Blake, Edward Joy, Louise E. Ander"
  },
  {
    "objectID": "index.html#who-is-this-manual-for",
    "href": "index.html#who-is-this-manual-for",
    "title": "R for Household Consumption and Expenditure Surveys",
    "section": "Who is this manual for?",
    "text": "Who is this manual for?\nThe goal of this manual is to provide a comprehensive introduction to these powerful technologies and to teach you how to use them to better understand your data and collaborate with others on your project.\nThroughout this manual, you will learn how to install and set up R and RStudio on your computer, as well as how to use them to perform data analysis, create visualizations, and manage your code. The manual includes step-by-step instructions, examples, and practice exercises to help you master these technologies.\nWhether you are a researcher, data scientist, or statistician, this manual will provide you with the skills and knowledge you need to start using R and RStudio for HCES analysis, to better understand your data and collaborate with others on your project.\nIt is important to note that this manual is not a comprehensive guide to R and RStudio but rather an introduction, designed to give you the foundational knowledge to start working with these technologies. There are many other resources available for learning more about these technologies, including online tutorials, forums, and documentation.\nWe hope you find this manual helpful and that it empowers you to work with these powerful tools."
  },
  {
    "objectID": "intro.html#software-requirements",
    "href": "intro.html#software-requirements",
    "title": "1  Introduction",
    "section": "1.1 Software requirements",
    "text": "1.1 Software requirements\nFirst, we will cover R, which is a powerful and versatile programming language that is widely used for data analysis, statistical modeling, and data visualization.\n\nIt is an open-source software that can be freely downloaded and used by anyone. R is widely used in academia, industry, and government, and is becoming increasingly popular among data scientists and analysts.\nIt is a great tool for those who have been using other statistics tools like Excel, SAS, SPSS and want to take their data analysis skills to the next level.\n\nThis training will provide an introduction to the basics of R and will give you the skills you need to start working with data in R..\nNext, we will introduce RStudio, which is a popular integrated development environment (IDE) for R.\n\nRStudio provides a user-friendly interface for working with R and makes it easy to work with R packages, which are collections of pre-written R code that can be used to perform specific tasks.\nWith RStudio, you will be able to write, test, and debug your R code, and easily share your work with others.\n\n\n\n\nsource: https://moderndive.netlify.app/1-getting-started.html\n\n\nThis manual will provide step-by-step instructions for installing and setting up R and RStudio on your computer. We will also go over basic concepts and commands for working with each technology, as well as provide examples of how to use them in different contexts. With this manual, you will have the skills and knowledge you need to start using these powerful technologies to better understand your data and collaborate with others on your project."
  },
  {
    "objectID": "intro.html#downloading-and-installing-r-and-rstudio",
    "href": "intro.html#downloading-and-installing-r-and-rstudio",
    "title": "1  Introduction",
    "section": "1.2 Downloading and Installing R and Rstudio",
    "text": "1.2 Downloading and Installing R and Rstudio\n\n\n1.2.1 Downloading and Installing R\n\nTo download R, you can visit the official R website at https://cran.r-project.org/. On the website, you will see links to download the latest version of R for Windows, Mac, and Linux. Once you have downloaded the installer for your operating system, you can run the installer and follow the prompts to install R on your computer.\nDownloading and installing R:\n\n\n\n\n\n\nInstructions for downloading and Installing R\n\n\n\n\n\nStep 1:\n\nStep 2:\n\nStep 3:\n\nStep 4:\n\nStep 5:\n\nStep 6:\n\nStep 7:\n\nStep 8:\n\n\n\n\n\n\n1.2.2 Downloading and Installing RStudio\nTo download RStudio, you can visit the official RStudio website at https://posit.co/download/rstudio-desktop/. On the website, you will see links to download the latest version of RStudio for Windows, Mac, and Linux. Once you have downloaded the installer for your operating system, you can run the installer and follow the prompts to install RStudio on your computer. \n\n\n\n\n\n\nInstructions for downloading and Installing Rstudio\n\n\n\n\n\nStep 1: Navigate to https://posit.co/download/rstudio-desktop/\n\nStep 2:\n\nStep 3:\n\nStep 4:\n\n\n\n\nPlease note that these are general instructions for a Microsoft Windows operating system, and depending on your system setup and security settings, some steps might be slightly different. Also, you will need to make sure that you have administrative access or permission to install the software on your computer.\nYou can also refer to the software website instruction or online tutorials that are specific to your operating system and setup.\nFrom here we will use the term R to refer to R and Rstudio or vice-versa.\n\n\n\nSource: https://docs.posit.co/ide/user/ide/guide/ui/ui-panes.html"
  },
  {
    "objectID": "intro.html#recommended-setup-while-using-this-book",
    "href": "intro.html#recommended-setup-while-using-this-book",
    "title": "1  Introduction",
    "section": "1.3 Recommended setup while using this book",
    "text": "1.3 Recommended setup while using this book\nStep 1: Download the training files from the following link: https://dzvoti.github.io/r4hces/r4hces-data.zip\nStep 2: Unzip the file and save it in a folder on your computer.\nStep 3: Open RStudio create a new project using an existing folder. Select the folder where you saved the training files."
  },
  {
    "objectID": "data_types.html#assignment",
    "href": "data_types.html#assignment",
    "title": "2  Data Types",
    "section": "2.1 Assignment",
    "text": "2.1 Assignment\nWe can store any of these datatypes in an object by assigning the value to that object. For example, we can assign the value Maize to the object food_name as follows:\n\nfood_name <- \"Maize\"\n\nThe <- is the assignment operator. It assigns the value on the right to the object on the left. We can then use the object food_name in other commands, for example, to print the value of food_name we can use the print() function:\n\n\n\n\n\n\n<-\n\n\n\nIf you are using RStudio, you can type <- by pressing the Alt key and - key at the same time.\n\n\n\nprint(food_name)\n\nThere are other assignment operators, such as = and ->, but <- is the most common. We can also assign the value of an object to another object, for example:\n\nfood_name2 <- food_name\n\nIn this case, the value of food_name is assigned to food_name2. We can then print the value of food_name2:\n\nprint(food_name2)\n\nIn this book we will use the <- and the = assignment operator. We use the <- when we want to assign a value to an object, and the = when we want to assign a value to an argument in a function. This is a convention that is used by many R programmers. More on functions later."
  },
  {
    "objectID": "data_types.html#character-data",
    "href": "data_types.html#character-data",
    "title": "2  Data Types",
    "section": "2.2 Character data",
    "text": "2.2 Character data\nThe simplest data type in R is the character. A character is a string of characters, for example, the “Maize” name that we assigned above. The “” indicate that we want to store the string of characters between the “” in the object. If we don’t use the “” then R will look for an object with that name, and if it doesn’t find it, it will throw an error. For example, if we type:\n\nfood_name <- Maize\n\nWe can fix this by putting the “” around the string of characters:\n\nfood_name <- \"Maize\"\n\nWe ca perform operations on character data, such as concatenation, which is the joining of two or more strings of characters. We can do this using the paste() function. For example, we can create a new character object called food_name3 by concatenating the values of food_name and food_name2 as follows:\n\n# Create character vector with value \"Maize\"\nfood_name <- \"Maize\"\n# Create character vector with value \"Meal\"\nfood_name2 <- \"Meal\"\n# Concatenate the values of food_name and food_name2 and assign the result to a new character object called food_name3\nfood_name3 <- paste(food_name, food_name2)\n# Print the value of food_name3\nprint(food_name3)"
  },
  {
    "objectID": "data_types.html#numeric-data",
    "href": "data_types.html#numeric-data",
    "title": "2  Data Types",
    "section": "2.3 Numeric data",
    "text": "2.3 Numeric data\nA numeric is a numerical value, such as the food quantity value. We can assign a numeric value to an object as follows:\n\nfood_quantity <- 0.5\n\nNote that we don’t need to put the “” around the numeric value. If we do, then R will treat it as a character, and not a numeric. For example, if we type:\n\nfood_quantity <- \"0.5\"\n\nWe can then do simple mathematical manipulations with a numeric value. For example, we can add 0.5 to the value of food_quantity as follows:\n\nfood_quantity <- 0.5\n# Add 0.5 to the value of food_quantity\nfood_quantity <- food_quantity + 0.5\n\n\n\n\n\n\n\nExercise\n\n\n\n\nCreate a character object called food_name and assign it the value \"Maize\".\nCreate another character object called food_subname and assign it the value \"Meal\".\nConcatenate the values of food_name and food_subname and assign the result to a new character object called full_name.\nCreate a numeric object called food_quantity_g and assign it the value 15.\nConvert the value of food_quantity_g to milligrams and assign the result to a new numeric object called food_quantity_mg.\n\n\n\n\n2.3.1 Operations on numeric data\nWe can perform operations on numeric data, such as addition, subtraction, multiplication and division. For example, we can create a new numeric object called food_quantity by adding the values of food_quantity_g and food_quantity_mg as follows:\n\n# Create a numeric object called food_quantity_g and assign it the value 15\nfood_quantity_g <- 15\n\n# Create a numeric object called food_quantity_mg and \n# calculate the value of food_quantity_g in milligrams\nfood_quantity_mg <- food_quantity_g * 1000\n\nJust like in maths the operators in R follow operator precedence.However we can use brackets to specify the order of operations."
  },
  {
    "objectID": "data_types.html#logical-data",
    "href": "data_types.html#logical-data",
    "title": "2  Data Types",
    "section": "2.4 Logical data",
    "text": "2.4 Logical data\nLogical data takes the values TRUE or FALSE. We can assign a logical value to an object as follows:\n\nis_staple <- TRUE\n\nLogical values can be returned from operation e.g. testing for equality. For example, we can test whether the vales in two objects is the same as follow:\n\n# Create character vectors\nfood_name <- \"Maize\"\nfood_name2 <- \"Maize\"\nfood_name3 <- \"Rice\"\n\n# Test equality\nfood_name == food_name2\nfood_name == food_name3\n\nNotice how when testing for equality we use ==? This is because the = is an assignment operator and not a logical operator. We can also use the != operator to test for inequality. For example, we can test whether the values in two objects are not the same as follows:\n\nfood_name != food_name2\nfood_name != food_name3\n\nOther logical operators are >, <, >= and <=. Logical object can be the subject of logical functions, notably \"if .. then\". Consider the example below:\n\n# Create numeric object\nage <- 18\n# Test whether age is greater than 18\nif(age > 18) {\n    print(\"You are an adult\")\n    }else{\n        print(\"You are not an adult\")\n        }\n\nTesting the same example with a different value of age:\n\n# Create numeric object\nage <- 17\n# Test whether age is greater than 18\nif(age > 18) {\n    print(\"You are an adult\")\n    }else{\n        print(\"You are not an adult\")\n        }\n\nLogical operations can be chained together using the & operator for \"and\" and the | operator for \"or\". For example, we can test whether the values in two objects are the same and whether the value of food_quantity_g is greater than 10 as follows:\n\nfood_name == food_name2 & food_quantity_g > 10"
  },
  {
    "objectID": "data_types.html#summary",
    "href": "data_types.html#summary",
    "title": "2  Data Types",
    "section": "2.5 Summary",
    "text": "2.5 Summary\nUntil now we have been storing only one value in an object. We can store multiple values in an object using a vector. We will look at vectors and data structures in the next section."
  },
  {
    "objectID": "data_structures.html#vectors",
    "href": "data_structures.html#vectors",
    "title": "3  Data Structures",
    "section": "3.1 Vectors",
    "text": "3.1 Vectors\nA vector is a series of homogeneous values of a variable (e.g. Foods from an HCES survey). The easiest way to form a vector of values in R is with the \"combine\" function c(). An example of a vector of character values (food_names) is shown below:\n\n# Create a vector of character values\nfood_names <-\n    c(\"Rice\",\n      \"Maize\",\n      \"Beans\",\n      \"Cassava\",\n      \"Potatoes\",\n      \"Sweet potatoes\",\n      \"Wheat\")\n\n#Create a vector of numeric values\nconsumpution <- c(0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.01)\n\n# Create a vector of logical values\nis_staple <- c(TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE)\n\n# Create a vector of mixed values\nmixture <- c(5.2, TRUE, \"CA\")\n\n\n\n\n\n\n\nExcercise\n\n\n\nUse print to see the values of the vectors above e.g print(food_names) What happens if you try to print the vector mixture?\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe can count the number of items in a vector with the length() function:\n\nlength(food_names)\n\nEach item in a vector can be referenced by its index (i.e. its position in the sequence of values), and we can pull out a particular item using the square brackets after the vector name. For example, the 3rd item in food_names can be accessed like this\n\nfood_names[3]"
  },
  {
    "objectID": "data_structures.html#data-frames-vs-tibbles",
    "href": "data_structures.html#data-frames-vs-tibbles",
    "title": "3  Data Structures",
    "section": "3.2 data frames vs tibbles",
    "text": "3.2 data frames vs tibbles\nIn R, data frames and tibbles are two common data structures used to store tabular data. While they are similar in many ways, there are some important differences to keep in mind.\n\n3.2.1 Data Frames\nData frames are a built-in R data structure that is used to store tabular data. They are similar to matrices, but with the added ability to store columns of different data types. Data frames are created using the data.frame() function, and can be manipulated using a variety of built-in R functions.\n\n\n3.2.2 Tibbles\nTibbles are a newer data structure that were introduced as part of the tidyverse package. They are similar to data frames, but with some important differences. Tibbles are created using the tibble() function, and can also be manipulated using a variety of built-in tidyverse functions.\nOne of the main differences between data frames and tibbles is how they handle column names. In a data frame, column names are stored as a character vector, and can be accessed using the $ operator. In a tibble, column names are stored as a special type of object called a quosure, which allows for more flexible and consistent handling of column names.\nAnother difference between data frames and tibbles is how they handle subsetting. In a data frame, subsetting using the [ ] operator can sometimes lead to unexpected results, especially when subsetting a single column. In a tibble, subsetting is more consistent and predictable, and is done using the [[ ]] operator or with user friendly dplyr function e.g. filter, select.\nOverall, while data frames and tibbles are similar in many ways, tibbles offer some important advantages over data frames, especially when working with the tidyverse package.\nLet us make a data frame using the data.frame() function. We will use the vectors we created above as the columns of the data frame. Note that the vectors must be of the same length, otherwise the data frame will be filled with NA values to make up the difference.\n\n# Create a data frame\nfood_df <-\n    data.frame(\n        food_names = c(\n            \"Rice\",\n            \"Maize\",\n            \"Beans\",\n            \"Cassava\",\n            \"Potatoes\",\n            \"Maize\",\n            \"Wheat\"\n        ),\n        consumption = c(0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.01),\n        is_staple = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE),\n        stringsAsFactors = TRUE\n    )\n\n# Print the data frame\nprint(food_df)\n\nLet us make a tibble using the tibble() function. We will use the vectors we created above as the columns of the tibble. Note that the vectors must be of the same length, otherwise the tibble will be filled with NA values to make up the difference.\n\n# Create a tibble\nfood_tb <- tibble::tibble(\n    food_names = c(\n        \"Rice\",\n        \"Maize\",\n        \"Beans\",\n        \"Cassava\",\n        \"Potatoes\",\n        \"Maize\",\n        \"Wheat\"\n    ),\n    consumption = c(0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.01),\n    is_staple = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE)\n)\n\n# Print the tibble\nprint(food_tb)\n\n\n\n\n\n\n\nExcercise\n\n\n\nUse the class() function to check the class of the food_df and food_tb objects. 1. What did you notice? 2. What is the difference between the two objects? Guess the data structure of each object. 3. Did you notice how the vector names were used as column names in the data frame and tibble?"
  },
  {
    "objectID": "data_structures.html#factors",
    "href": "data_structures.html#factors",
    "title": "3  Data Structures",
    "section": "3.3 Factors",
    "text": "3.3 Factors\nNote that a factor is actually a vector, but with an associated list of levels, always presented in alpha-numeric order. These are used by R functions such as lm() which does linear modelling, such as the analysis of variance. We shall see how factors can be used in the later section on data frames.\nLet us create a factor from a vector of character values. We can do this using the factor() function. The first argument is the vector of character values, and the second is the list of levels. If we don’t specify the levels, R will use the unique values in the vector, in alphabetical order.\n\n3.3.1 Coercing a vector to a factor\nExample of converting the food_names vector to a factor:\n\n# Create a factor without providing the levels argument\nfood_names_factor_1 <- factor(food_names)\n# Print the factor\nprint(food_names_factor_1)\n\n# Create a factor from a vector of character values\nfood_names_factor_2 <-\n    factor(\n        food_names,\n        levels = c(\n            \"Rice\",\n            \"Maize\",\n            \"Beans\",\n            \"Cassava\",\n            \"Potatoes\",\n            \"Sweet potatoes\",\n            \"Wheat\"\n        )\n    )\n\n# Print the factor\nprint(food_names_factor_2)\n\n\n\n\n\n\n\nExcercise\n\n\n\n\nWhat is the difference between the two factors?\nCreate a factor from the is_staple vector. What are the levels?\nCreate a factor from the consumption vector. What are the levels?\n\n\n\n\n\n3.3.2 Coercing a vector to a factor in a data frame\nExample of converting the food_names vector to a factor in a data frame:\n\nlibrary(dplyr)\n# Use the food_tb data frame created above and convert the food_names column to a factor\nfood_tb <- mutate(food_tb, food_names = factor(food_names))\n\n# Print the data frame\nprint(food_tb)"
  },
  {
    "objectID": "data_structures.html#summary",
    "href": "data_structures.html#summary",
    "title": "3  Data Structures",
    "section": "3.4 Summary",
    "text": "3.4 Summary\nThere are other data structures in R, e.g. Matrix and lists but these are the most common. We will now look at some of the operations we can perform on vectors and data frames in the future sections.\nBut first,we introduced the dplyr package above. This is a package which provides a set of functions for manipulating data frames. We will use it extensively in this book. We can use the mutate() function to add a new column to a data frame. In this case we are adding a new column called food_names which is a factor version of the food_names column in the data frame.This means we introduced a new function mutate() and a new package dplyr.\nIn the next section we define what are packages and functions."
  },
  {
    "objectID": "packages_and_functions.html#functions",
    "href": "packages_and_functions.html#functions",
    "title": "4  Packages and Functions",
    "section": "4.1 Functions",
    "text": "4.1 Functions\nFunctions are a set of instructions that can be called by name. They are useful for automating repetitive tasks and for encapsulating complex tasks.\nFunctions are defined using the function() function. An example of a function is the dataframe function which we used above to create a dataframe.\nA function takes in one or more arguments and returns a value. The arguments are specified in the function definition and the value is returned using the return() function.\nTo see the arguments of a function, use the ? before the function name e.g. ?dataframe. To see the code of a function, just type the function name without the parentheses.\nFor example, to see the code of the dataframe function, type dataframe without the parentheses. Other examples are head , str and summary functions.\n\n4.1.1 Creating a function\nThe basic syntax for defining a function is as follows:\n\n# Define a function\nfunction_name <- function(arg1, arg2, ...) {\n    # Function body\n    # ...\n    # Return value\n    return(return_value)\n}\n\nFor example, let us create a function called add that takes in two arguments and returns the sum of the two arguments.\n\n# Define a function\nadd <- function(x, y) {\n    # Return the sum of the two arguments\n    return(x + y)\n}\n\n# Call the function\nadd(5, 3)\n\n[1] 8"
  },
  {
    "objectID": "packages_and_functions.html#packages",
    "href": "packages_and_functions.html#packages",
    "title": "4  Packages and Functions",
    "section": "4.2 Packages",
    "text": "4.2 Packages\nA package is a collection of functions, data, and documentation that extends the functionality of R. There are thousands of packages available for R.\nTo use a package, you first need to install it using the install.packages() function. Once installed, you can load the package using the library() function.\nFor example, to install the dplyr package, you would type install.packages(\"dplyr\").\nTo load the dplyr package, you would type library(dplyr). To see the functions in a package, type help(package = \"package_name\") e.g. help(package = \"dplyr\").\nTo see the code of a function in a package, type package_name::function_name e.g. dplyr::mutate. You can also use the ? before the function name e.g. ?dplyr::mutate.\n\n4.2.1 Package sources\nThere are three main sources of packages for R:\n\nCRAN - The Comprehensive R Archive Network: https://cran.r-project.org/. This is the main source of packages for R. It contains over 15,000 packages. To install a package from CRAN, you can use the install.packages() function.\nGitHub: Most developers store their packages on GitHub. To install a package from GitHub, you can use the install_github() function from the devtools package. e.g. devtools::install_github(\"dzvoti/hcesNutR\").\n\n\n\n\n\n\n\nTip\n\n\n\nNotice how we used package_name::function_name to call the install_github() function.\n\n\n\n\n4.2.2 Loading packages\nOnce installed a package need to be ‘loaded’ for its function to be available in R. This is done using the library() function.\nFor example, to load the dplyr package, you would type require(dplyr). The difference between the two functions is that library() will throw an error if the package is not installed, while require() will throw a warning. You can also use the :: operator to call a function from a package without loading the package.\nAlso,to call the mutate() function from the dplyr package without loading the package, you would type dplyr::mutate(). This is useful when you want to use a function from a package without loading the package.\n\n\n4.2.3 Removing packages\nTo remove a package, you can use the remove.packages() function. For example, to remove the dplyr package, you would type remove.packages(\"dplyr\").\n\n\n4.2.4 Updating packages\nTo update a package, you can use the update.packages() function. For example, to update the dplyr package, you would type update.packages(\"dplyr\").\n\n\n4.2.5 Listing installed packages\nTo list all installed packages, you can use the installed.packages() function. For example, to list all installed packages, you would type installed.packages().\n\n\n4.2.6 Recomended packages\nThere are thousands of packages available for R. However, there are some packages that are recommended for beginners. These include:\n\nRecommended Packages {.striped .hover}\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\ntidyverse\nA collection of packages designed for data science. It includes the: dplyr, ggplot2, tidyr, readr, purrr, tibble, stringr, forcats and haven packages.\n\n\nhere\nA package for managing file paths.\n\n\n\nNow that we know what packages and functions are, let us look at some of the functions we can use to manipulate vectors and dataframes in the next section on Data Import,Wrangling and Export."
  },
  {
    "objectID": "data_wrangling_and_io.html#data-inputimport",
    "href": "data_wrangling_and_io.html#data-inputimport",
    "title": "5  Data I/O and Wrangling",
    "section": "5.1 Data Input/Import",
    "text": "5.1 Data Input/Import\nThere are many ways to import data into R. In this section we will look at how to import data from a CSV file, an Excel file and Stata file. In the sample data folder there are *.csv files and stata files *.dta. Foe example to import the health data from a survey stored in hh_mod_a_filt_vMAPS.dta stored in the mwi-ihs5-sample-data folder within our working directory we run:\n\n# Load the haven package\nlibrary(haven)\n\n# Import roster data\nihs5_roster <- read_dta(here::here(\"data\",\"mwi-ihs5-sample-data\", \"hh_mod_a_filt_vMAPS.dta\"))\n\n# Preview the data\nhead(ihs5_roster )\n\nTo read a csv file we use the read_csv() function from the readr package. For example, to import the IHS5_UNIT_CONVERSION_FACTORS_vMAPS.csv file stored in the mwi-ihs5-sample-data folder within our working directory we run:\n\n# Load the readr package\nlibrary(readr)\n\n# Import unit conversion factors data\nihs5_unit_conversion_factors <- read_csv(here::here(\"data\",\"mwi-ihs5-sample-data\", \"IHS5_UNIT_CONVERSION_FACTORS_vMAPS.csv\"))\n\n# Preview the data\nhead(ihs5_unit_conversion_factors)\n\n\n\n\n\n\n\nExcercise\n\n\n\n\nImport your own excel file into R.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNotice how all import operations are done within the here::here() function. This is because we are using the here package to manage file paths. The here::here() function returns the path to the file relative to the working directory. This is useful when you want to share your code with others, as they can run the code without having to change the file paths.\nIt is very import that file names and directories are typed as they are. R is sensitive to capital letters and spaces. For example, if you type IHS5_UNIT_CONVERSION_FACTORS_VMAPS.csv instead of IHS5_UNIT_CONVERSION_FACTORS_vMAPS.csv, R will throw an error. To get around this in RStudio use the tab key to autocomplete file names and directories.\n\n\nAfter importing files they are usually stored in memory as dataframes/tibbles. We can check the class of an object using the class() function. For example, to check the class of the ihs5_roster object, we would type class(ihs5_roster). We can also check the structure of an object using the str() function. For example, to check the structure of the ihs5_roster object, we would type str(ihs5_roster). We want to make sure that the data is imported correctly before we start manipulating it."
  },
  {
    "objectID": "data_wrangling_and_io.html#data-wrangling",
    "href": "data_wrangling_and_io.html#data-wrangling",
    "title": "5  Data I/O and Wrangling",
    "section": "5.2 Data Wrangling",
    "text": "5.2 Data Wrangling\nThe dplyr package from the tidyverse package is our data wrangling tool of choice. It provides a set of functions for manipulating dataframes e.g. renaming columns, conditional removal of rows, creation of other columns and so on. We will load and manipulate the consumption module of our hypothetical Malawi IHS5 survey data. The data is stored in the mwi-ihs5-sample-data folder within our working directory and is called HH_MOD_G1_vMAPS.dta. We will use the here package to manage file paths.\n\nlibrary(dplyr) # data manipulation\nlibrary(haven) # data import\nlibrary(here) # file paths\n\n\n5.2.1 Import the data\n\n# Import the data\nihs5_consumption <- read_dta(here::here(\"data\",\"mwi-ihs5-sample-data\", \"HH_MOD_G1_vMAPS.dta\"))\n\n\n\n\n\n\n\nExcercise\n\n\n\n\nCheck if the data improrted correctly\nCheck the structure of the data\nHow many observations and variables are there?\n\n\n\n\n\n5.2.2 Subsetting data\n\n\n5.2.3 Subsetting data frames\nThere are a number of functions that can be used to extract subsets of R objects in tidyverse syntax. The most important are the following from the dplyr package:\n\nfilter() allows you to select a subset of rows in a data frame.\nselect() allows you to select a subset of columns in a data frame.\narrange() allows you to reorder the rows of a data frame.\nmutate() allows you to create new columns from existing columns.\nsummarise() allows you to collapse many values down to a single summary.\npull() allows you to extract a single column from a data frame as a vector.\n\n\n\n5.2.4 Subsetting columns\nThis data that we loaded is a randomly generated immitation of the Malawi Intergrated Household Survey 2018-2019 described here. This data contains responses on total consumption as well as disaggregation of the sources of these foods.In this book we will process only the `total consumption.\nRemember we said that our data is loaded in memory? Seeing that the ihs5_consumption data contains columns we do not need let us subset it. The select function in dplyr is very useful for this. For example to keep only the columns with household identifiers and food names, units and quantity of consumption we keep the following columns in our data; “case_id”, “HHID”, “hh_g01”, “hh_g01_oth”, “hh_g02”, “hh_g03a”, “hh_g03b”, “hh_g03b_label”, “hh_g03b_oth”, “hh_g03c”, “hh_g03c_1”.\n\n# Subset the data\nihs5_consumption_subset <-\n    select(\n        ihs5_consumption,\n        case_id,\n        HHID,\n        hh_g01,\n        hh_g01_oth,\n        hh_g02,\n        hh_g03a,\n        hh_g03b,\n        hh_g03b_label,\n        hh_g03b_oth,\n        hh_g03c,\n        hh_g03c_1\n    )\n\nThe syntax for most tidyverse functions is function (data,columns). Notice that we stored the subsetting operation in a new object called ihs5_consumption_subset? This is generally frowned upon unless we intend to use the original dataset for separate operations. Storing the subset in a new object will use up more memory to store the 2 objects. We can overwrite the original object by typing:\n\nihs5_consumption <- select(\n    ihs5_consumption,\n    case_id,\n    HHID,\n    hh_g01,\n    hh_g01_oth,\n    hh_g02,\n    hh_g03a,\n    hh_g03b,\n    hh_g03b_label,\n    hh_g03b_oth,\n    hh_g03c,\n    hh_g03c_1\n)\n\n\n\n\n\n\n\nTip\n\n\n\nInstead of typing the column names, we can use the : operator to select a range of columns. For example, to select all the columns between case_id and hh_g03c_1 we would type:\n\n# Subset the data\nihs5_consumption_subset <-\n    select(\n        ihs5_consumption,\n        case_id:hh_g03c_1\n    )\n\n\n\nNext let us give the columns more meaningful names. We can do this using the rename function. For example, to rename the hh_g01 column to consumedYN and hh_g02 to food_item, we would type:\n\n# Rename the columns\nihs5_consumption <-\n    rename(ihs5_consumption,\n           consumedYN = hh_g01,\n           food_item = hh_g02)\n\nNotice how our operations only affect the specific columns we specify? This is because the select and rename functions are smart and intiutive.\n\n\n\n\n\n\nExcercise\n\n\n\n\nRename the remaining columns to:\n\n\n\n\nold_name\nnew_name\n\n\n\n\nhh_g01_oth\nfood_item_other\n\n\nhh_g03a\nconsumption_quantity\n\n\nhh_g03b\nconsumption_unit\n\n\nhh_g03b_label\nconsumption_unit_label\n\n\nhh_g03b_oth\nconsumption_unit_oth\n\n\nhh_g03c\nconsumption_subunit_1\n\n\nhh_g03c_1\nconsumption_subunit_2\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nSolution:\n\n# Reload the data to start from scratch\nihs5_consumption <-\n    read_dta(here::here(\"data\",\n                        \"mwi-ihs5-sample-data\", \n                        \"HH_MOD_G1_vMAPS.dta\"))\n\n# Rename the columns\nihs5_consumption <-\n    rename(\n        ihs5_consumption,\n        consumedYN = hh_g01,\n        food_item = hh_g02,\n        food_item_other = hh_g01_oth,\n        consumption_quantity = hh_g03a,\n        consumption_unit = hh_g03b,\n        consumption_unit_label = hh_g03b_label,\n        consumption_unit_oth = hh_g03b_oth,\n        consumption_subunit_1 = hh_g03c,\n        consumption_subunit_2 = hh_g03c_1\n    )\n\n\n\n\n\n\n5.2.5 Subsetting rows\nWe can also subset rows using the filter function. For example, to keep only the rows where consumedYN is equal to 1, we would type:\n\n# Subset the data\nihs5_consumption <- filter(ihs5_consumption, consumedYN == 1)\n\nNotice how we are using the logical operator == to test each row whether the value of consumedYN is equal to 1? This is called a conditional statement as we discussed in the previous sections."
  },
  {
    "objectID": "data_wrangling_and_io.html#chaining-operations-using-the-pipe-operator",
    "href": "data_wrangling_and_io.html#chaining-operations-using-the-pipe-operator",
    "title": "5  Data I/O and Wrangling",
    "section": "5.3 Chaining operations using the pipe operator",
    "text": "5.3 Chaining operations using the pipe operator\nWe can chain operations using the pipe operator %>% or |>. This is useful when we want to perform multiple operations on a dataset. For example, to read, subset the data and rename the columns in one operation, we would type:\n\n# Read, subset and rename the data\nihs5_consumption <-\n    read_dta(here::here(\"data\",\n                        \"mwi-ihs5-sample-data\", \n                        \"HH_MOD_G1_vMAPS.dta\")) |>\n    select(\n        case_id,\n        HHID,\n        hh_g01,\n        hh_g01_oth,\n        hh_g02,\n        hh_g03a,\n        hh_g03b,\n        hh_g03b_label,\n        hh_g03b_oth,\n        hh_g03c,\n        hh_g03c_1\n    ) %>%\n    rename(\n        consumedYN = hh_g01,\n        food_item = hh_g02,\n        food_item_other = hh_g01_oth,\n        consumption_quantity = hh_g03a,\n        consumption_unit = hh_g03b,\n        consumption_unit_label = hh_g03b_label,\n        consumption_unit_oth = hh_g03b_oth,\n        consumption_subunit_1 = hh_g03c,\n        consumption_subunit_2 = hh_g03c_1\n    )\n\nWe deliberately used both the pipe operators %>% and |> to show that they are the same. The %>% is the most popular of the tidyverse pipes from the magrittr package.\nRecent versions (circa 2020) intoduced the native R pipe |>. The pipe operator is useful when we want to perform multiple operations on a dataset without storing the intermediate results in memory.\nIn the above example we only stored the final result in memory. This is useful when we are working with large datasets and want to save memory.\n\n\n\n\n\n\nPipes\n\n\n\nIn Rstudio you can type the pipe operator by typing Ctlr + shift + m. You can also change whether the pipe operator is %>% or |> in the Tools > Global Options > Code > Editing menu by changing the Use native pipe operator |> (requires R 4.1+) option.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhen chaining operations we do not need to specify the data argument in the subsequent functions. This is because the output of the previous function is passed to the next function. If we want to specify the data argument, we can use the . symbol. For example, to specify the data argument in the rename function, we would type:\n\n\n\n5.3.1 Change the data type of a column\nThe mutate function is used to create new columns from existing columns. It is also used to change the data type of a column. For example, to change the data type of the consumption_quantity column to numeric, we would type:\n\nihs5_consumption <- ihs5_consumption |>\n    mutate(food_item_code = as.character(food_item))\n\n\n\n5.3.2 Create a new column\nAs we mentioned earlier, the mutate function is used to create new columns from existing columns. For example, to create a new column with hh_members (randomly generated) we would type:\n\nihs5_consumption <- ihs5_consumption |>\n    mutate(hh_members = sample(1:10, nrow(ihs5_consumption), replace = TRUE))\n\nHere we are using the sample function to generate random numbers between 1 and 10. The nrow function returns the number of rows in the ihs5_consumption data. The replace = TRUE argument tells the sample function to sample with replacement. This means that the same number can be sampled more than once. If we want to sample without replacement we would type replace = FALSE.\nWe used the sample function a lot during the generation of the sample data used in this book. You can see more on this in the data generation section.\n\n\n5.3.3 Vectorised operations\nThe mutate function is also useful for vectorised operations. For example, to create a new column with the consumption per person we would type:\n\nihs5_consumption <- ihs5_consumption |>\n    mutate(consumption_per_person = consumption_quantity / hh_members)\n\n\n\n\n\n\n\nExcercise\n\n\n\nSuppose this data is from a 7 day recall survey. Create a new column with the consumption per person per day.\n\n\n\n\n5.3.4 Enriching data\nWe can enrich our data by joining different files using the join function. The most common joins are left_join, right_join, inner_join and full_join.\nThe left_join function joins two dataframes by keeping all the rows in the first dataframe and matching the rows in the second dataframe.\nMost joining operations in hces data analysis are left_join operations as we want to keep all the rows in the primary data we are processing and enrich it with matched rows in the other data. For example, to join the ihs5_consumption data with the ihs5_household_identifies contained in hh_mod_a_filt_vMAPS.dta data we would type:\n\n# Import the data\nihs5_household_identifiers <-\n    read_dta(here::here(\"data\",\n                        \"mwi-ihs5-sample-data\", \n                        \"hh_mod_a_filt_vMAPS.dta\"))\n\n# Join the data\nihs5_consumption_j1 <- ihs5_consumption |>\n    left_join(ihs5_household_identifiers, by = \"HHID\")\n\nThe result is an enriched dataset with rows from the ihs5_household_identifiers data that match the HHID column in the ihs5_consumption data. The by argument tells the left_join function which column to use to match the rows. If the column names are the same in both dataframes, we do not need to specify the by argument. For example, to join the ihs5_consumption data with the ihs5_household_identifies contained in hh_mod_a_filt_vMAPS.dta data we would type:\n\n# Import the data\nihs5_household_identifiers <-\n    read_dta(here::here(\"data\",\n                        \"mwi-ihs5-sample-data\", \n                        \"hh_mod_a_filt_vMAPS.dta\"))\n\n# Join the data\nihs5_consumption <- ihs5_consumption |>\n    left_join(ihs5_household_identifiers)\n\n\n\n\n\n\n\nExcercise\n\n\n\n\nCompare the results of the two joins.\nWhat is the difference?\n\n\n\n\n\n5.3.5 Grouping and Summarising Data\nWe can group data using the group_by function. Grouping data is useful when we want to summarise data. In dplyr the summaries are created from the groups in the data. For eample to summarise the consumption_per_person by food_item we would type:\n\n# Summarise the data\nihs5_consumption_summary <- ihs5_consumption |>\n    group_by(food_item) |>\n    summarise(consumption_per_person = mean(consumption_per_person, na.rm = TRUE))\n\nHere we are using the mean function to calculate the mean of the consumption_per_person column. The na.rm = TRUE argument tells the mean function to ignore missing values.\nWe can also compute multiple summaries at once. For example, to compute the mean and standard deviation of the consumption_per_person column we would type:\n\n# Summarise the data\nihs5_consumption_summary <- ihs5_consumption |>\n    group_by(food_item) |>\n    summarise(\n        consumption_per_person_mean = mean(consumption_per_person, na.rm = TRUE),\n        consumption_per_person_sd = sd(consumption_per_person, na.rm = TRUE)\n    )\n\nTo compute summaries across multiple groups we can use the group_by function with multiple arguments. For example, to compute the mean and standard deviation of the consumption_per_person column by food_item and region we would type:\n\n# Summarise the data\nihs5_consumption_summary <- ihs5_consumption |>\n    group_by(food_item, region) |>\n    summarise(\n        consumption_per_person_mean = mean(consumption_per_person, na.rm = TRUE),\n        consumption_per_person_sd = sd(consumption_per_person, na.rm = TRUE)\n    )\n\nIn the next section we will learn how to use plots to visualise our data. A basic example of a plot is a bar chart. For example we can visualise the consumption per person by food item using a bar chart. To do this we will use the ggplot2 package from the tidyverse package like so:\n\n# Load the ggplot2 package\nlibrary(ggplot2)\n\n#  Plot the data\nihs5_consumption |>\n    # Add plot aesthetics\n    ggplot(aes(x = region, y = consumption_per_person, group = region)) +\n    # Add plot type\n    geom_boxplot() \n\nHere we plotted a boxplot of the consumption_per_person by region.\n\n\n5.3.6 Data Output/Export\nWe can export data from R using the write_csv() function from the readr package. For example, to export the ihs5_consumption data to a csv file called ihs5_consumption.csv stored in our working directory we run:\n\n# Export the data\nwrite_csv(ihs5_consumption, here::here(\"data\",\n                                       \"ihs5_consumption.csv\"))\n\nWe recommend exporting files to csv as this allows interoperability between various software. If you prefer exporting your data to excel, you can use the write_xlsx() function from the writexl package. For example, to export the ihs5_consumption data to an excel file called ihs5_consumption.xlsx stored in our working directory we run:\n\n# Export the data\nwritexl::write_xlsx(ihs5_consumption, here::here(\"ihs5_consumption.xlsx\"))\n\nTo export the data to a stata file, we can use the write_dta() function from the haven package. For example, to export the ihs5_consumption data to a stata file called ihs5_consumption.dta stored in our working directory we run:\n\n# Export the data\nwrite_dta(ihs5_consumption, here::here(\"ihs5_consumption.dta\"))"
  },
  {
    "objectID": "hcesNutR-package.html#reporting-bugs",
    "href": "hcesNutR-package.html#reporting-bugs",
    "title": "7  hcesNutR Package",
    "section": "7.1 Reporting bugs",
    "text": "7.1 Reporting bugs\nPlease report any bugs or issues here."
  },
  {
    "objectID": "hcesNutR-package.html#installation",
    "href": "hcesNutR-package.html#installation",
    "title": "7  hcesNutR Package",
    "section": "7.2 Installation",
    "text": "7.2 Installation\nYou can install the development version of hcesNutR from GitHub with:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"dzvoti/hcesNutR\")\n\nAs we discussed in previous chapters you need to load the package in your R session before you can use it. You can load the package by running the following code in your R console.\n\nlibrary(hcesNutR)"
  },
  {
    "objectID": "hcesNutR-package.html#functions-in-the-package",
    "href": "hcesNutR-package.html#functions-in-the-package",
    "title": "7  hcesNutR Package",
    "section": "7.3 Functions in the package",
    "text": "7.3 Functions in the package\nYou can view the functions in the package by running the following code in your R console.\n\nls(\"package:hcesNutR\")\n\n\n\n\n\n\n\nTip\n\n\n\nYou can read the functions and their description on the project website at: dzvoti.github.io/hcesNutR/reference/index.html"
  },
  {
    "objectID": "hcesNutR-package.html#sample-data",
    "href": "hcesNutR-package.html#sample-data",
    "title": "7  hcesNutR Package",
    "section": "7.4 Sample data",
    "text": "7.4 Sample data\nThe data used in this example is randomly generated to mimic the structure of the Fifth Integrated Household Survey 2019-2020 an HCES of Malawi. The variables and structure of this data is found here\n\n\n\n\n\n\nTip\n\n\n\nAll functions in this package take a dataframe/tibble as input data. This is by design to allow flexibility on input data. The example used here is for use on stata files with .dta but the functions should work with .csv files as well.\n\n\n\n7.4.1 Import and explore the sample data\nImport the sample data from the r4hces-data/mwi-ihs5-sample-data folder. Use the read_dta function from the haven package to import it.\n\n# Import the data using the haven package from the tidyverse\nsample_hces <-\n  haven::read_dta(here::here(\"data\", \n                             \"mwi-ihs5-sample-data\",\n                             \"HH_MOD_G1_vMAPS.dta\"))\n\n\n\n7.4.2 Trim the data\nIn this example we will use hcesNutR functions to demonstrate processing of total consumption data. The total consumption data is the data that contains the total consumption of each food item by each household.\nThe other consumption columns contain values for consumption from sources i.e. gifted, purchased, ownProduced. The workflow for processing the “other” consumption data is the same as demonstrated below.\n\n# Trim the data to total consumption\nsample_hces <- sample_hces |>\n  dplyr::select(case_id:HHID,\n                hh_g01:hh_g03c_1)"
  },
  {
    "objectID": "hcesNutR-package.html#hcesnutr-workflow",
    "href": "hcesNutR-package.html#hcesnutr-workflow",
    "title": "7  hcesNutR Package",
    "section": "7.5 hcesnutR Workflow",
    "text": "7.5 hcesnutR Workflow\n\n7.5.1 Column Naming Conventions and Renaming\nThe sample_hces data is in stata format which contains data with short column name codes that have associated “question” labels that explain the contents of the data. To make the column names more interpretable, the package provides the rename_hces function, which can be used to rename the column codes to standard hces names used downstream.\nThe rename_hces function uses column names from the standard_name_mappings_pairs dataset within the package. Alternatively, a user can create their own name pairs or manually rename their columns to the standard names.\nIt is important to note that all downstream functions in the hcesNutR package work with standard names and will not work with the short column names. Therefore, it is recommended to use the rename_hces() function to ensure that the column names are consistent with the package’s naming conventions.\nFor more information on how to use the rename_hces function, please refer to the function’s documentation: rename_hces.\n\n# Rename the variables\nsample_hces <- hcesNutR::rename_hces(sample_hces,\n                                     country_name = \"MWI\",\n                                     survey_name = \"IHS5\")\n\n\n\n7.5.2 Remove unconsumed food items\nHCES surveys administer a standard questionaire to each household where they are asked to conform whether they consumed the food items on their standard list. If a household did not consume a food item, the value of the ‘consYN’ is set to a constant. The remove_unconsumed function removes all food items that were not consumed by the household. The function takes in a data frame and the name of the column that contains the consumption information. The function also takes in the value that indicates that the food item was consumed.\n\n# Remove unconsumed food items\nsample_hces <- hcesNutR::remove_unconsumed(sample_hces,\n                                           consCol = \"consYN\", \n                                           consVal = 1)\n\n\n\n7.5.3 Create two columns from each dbl+lbl column\nThe create_dta_labels function creates two columns from each dbl+lbl (double plus label) column. The first column contains the numeric values and the second column contains the labels. The function takes in a data frame and finds all columns that contains the double plus label column. The function returns a data frame with the new columns.\n\n# Split dbl+lbl columns\nsample_hces <- hcesNutR::create_dta_labels(sample_hces)\n\n\n\n7.5.4 Concatenate columns\nSome HCES data surveys split consumed food items or their consumption units into multiple columns. The concatenate_columns function cleans the data by combining the split columns into one column. The function can exclude values from contatenation by specifying the whole or part of values to be excluded.\n\nConcatenate food item names\n\n# Merge food item names\nsample_hces <-\n  hcesNutR::concatenate_columns(sample_hces,\n                                c(\"item_code_name\", \n                                  \"item_oth\"),\n                                \"SPECIFY\",\n                                \"item_code_name\")\n\n\n\nConcatenate food item units\n\n# Merge consumption unit names. For units it is essential to remove parentesis as they are the major cause of duplicate units\nsample_hces <-\n  hcesNutR::concatenate_columns(\n    sample_hces,\n    c(\n      \"cons_unit_name\",\n      \"cons_unit_oth\",\n      \"cons_unit_size_name\",\n      \"hh_g03c_1_name\"\n    ),\n    \"SPECIFY\",\n    \"cons_unit_name\",\n    TRUE\n  )\n\n\n\n\n\n\n\nTip\n\n\n\nUse the select and rename functions from the dplyr package to subset the columns containing food item name , food item code, food unit name and food unit code. This is to ensure that the names are meaningful and consistent with the package’s naming conventions.\n\n\n\nsample_hces <- sample_hces |>\n  dplyr::select(\n    case_id,\n    hhid,\n    item_code_name,\n    item_code_code,\n    cons_unit_name,\n    cons_unitA,\n    cons_quant\n  ) |>\n  dplyr::rename(food_name = item_code_name,\n                food_code = item_code_code,\n                cons_unit_code = cons_unitA)\n\n\n\n\n7.5.5 Match survey food items to standard food items\nThe match_food_names function is useful for standardising survey food names. This is feasible due to an internal dataset of standard food item names matched with their corresponding survey food names for supported surveys. Alternatively users can use their own food matching names by passing a csv to the function. See hcesNutR::food_list for csv structure.\n\nsample_hces <-\n  match_food_names_v2(\n    sample_hces,\n    country = \"MWI\",\n    survey = \"IHS5\",\n    food_name_col = \"food_name\",\n    food_code_col = \"food_code\",\n    overwrite = FALSE\n  )\n\n\n\n7.5.6 Match survey consumption units to standard consumption units\nThe match_food_units_v2 function is useful for standardising survey consumption units. This is feasible due to an internal dataset of standard consumption units matched with their corresponding survey consumption units for supported surveys. Alternatively users can download our template from hcesNutR::unit_names_n_codes_df and modify it to use their own consumption unit matching names.\n\nsample_hces <-\n  match_food_units_v2(\n    sample_hces,\n    country = \"MWI\",\n    survey = \"IHS5\",\n    unit_name_col = \"cons_unit_name\",\n    unit_code_col = \"cons_unit_code\",\n    matches_csv = NULL,\n    overwrite = FALSE\n  )\n\n\n\n7.5.7 Add regions and districts to the data\nIdentify the HCES module that contains household identifiers. In some cases this will already be present in the HCES data and should be skipped. From the household identifiers select the ones that are required and add to the data. In this example we will add the region and district identifiers to the data from the hh_mod_a_filt.dta file.\n\n# Import household identifiers from the hh_mod_a_filt.dta file\nhousehold_identifiers <-\n  haven::read_dta(here::here(\"data\",\n                             \"mwi-ihs5-sample-data\",\n                             \"hh_mod_a_filt_vMAPS.dta\")) |>\n  # subset the identifiers and keep only the ones needed.\n  dplyr::select(case_id,\n                HHID,\n                region) |>\n  dplyr::rename(hhid = HHID)\n\n# Add the identifiers to the data\nsample_hces <-\n  dplyr::left_join(sample_hces,\n                   household_identifiers,\n                   by = c(\"hhid\", \"case_id\"))\n\n\n\n7.5.8 Create a measure_id column\nThe create_measure_id function creates a measure id column that is used to identify the consumption measure of each food item. The function takes in a data frame and the name of the column that contains the consumption information. The function also takes in the value that indicates that the food item was consumed.\nThe measure_id is a unique identifier that allows us to join the consumption data with the food conversion factors data.\n\n# Create measure id column\nsample_hces <-\n  create_measure_id(\n    sample_hces,\n    country = \"MWI\",\n    survey = \"IHS5\",\n    cols = c(\"region\",\n             \"matched_cons_unit_code\",\n             \"matched_food_code\"),\n    include_ISOs = FALSE\n  )\n\n\n\n7.5.9 Import food conversion factors.\nThe available data comes with a `food_conversion fcators file which has conversion fcators that link the food names and units to their corresponding\n\n# Import food conversion factors file\nIHS5_conv_fct <-\n  readr::read_csv(\n    here::here(\n      \"data\",\n      \"mwi-ihs5-sample-data\",\n      \"IHS5_UNIT_CONVERSION_FACTORS_vMAPS.csv\"\n    )\n  )\n\nWe need to check if the conversion factors file contain all the expected conversion factors for the hces data being processed. The check_conv_fct function checks if the conversion factors file contains all the expected conversion factors for the hces data being processed. T\n\n\n\n\n\n\nWarning\n\n\n\nRemember this data was randomly generated so it is expected that the weights will not be realistic. Also not all food items have conversion factors so the weight of those food items will be NA.\n\n\n\n# Check conversion factors \ncheck_conv_fct(hces_df = sample_hces, \n               conv_fct_df = IHS5_conv_fct)\n\n\n\n7.5.10 Calculate weight of food items in kilograms.\nThe apply_wght_conv_fct function will take the hces_df and conv_fct_df and calculate the weight of each food item in kilograms.\n\n\n\n\n\n\nWarning\n\n\n\nRemember this data was randomly generated so it is expected that the weights will not be realistic. Also not all food items have conversion factors so the weight of those food items will be NA.\n\n\n\nsample_hces <-\n  apply_wght_conv_fct(\n    hces_df = sample_hces,\n    conv_fct_df = IHS5_conv_fct,\n    factor_col = \"factor\",\n    measure_id_col = \"measure_id\",\n    wt_kg_col = \"wt_kg\",\n    cons_qnty_col = \"cons_quant\",\n    allowDuplicates = TRUE\n  )\n\n\n\n7.5.11 Calculate AFE/AME and add to the data\n\n\n\n\n\n\nAssumptions\n\n\n\nThe ame/afe factors are calculated using the following assumptions: - Merge HH demographic data with AME/AFE factors - Men’s weight: 65kg (assumption) - Women’s weight: 55kg (from DHS) - PAL: 1.6X the BMR\n\n\n\nImport data required\nIn order to calculate the AFE and AME metrics we require the following data: - Household roster with the sex and age of each individual HH_MOD_B_vMAPS.dta - Household health HH_MOD_D_vMAPS.dta - AFE and AME factors IHS5_AME_FACTORS_vMAPS.csv and IHS5_AME_SPEC_vMAPS.csv\n\n# Import data of the roster and health modules of the IHS5 survey\nihs5_roster <-\n  haven::read_dta(here::here(\"data\",\n                             \"mwi-ihs5-sample-data\",\n                             \"HH_MOD_B_vMAPS.dta\"))\nihs5_health <-\n  haven::read_dta(here::here(\"data\",\n                             \"mwi-ihs5-sample-data\",\n                             \"HH_MOD_D_vMAPS.dta\"))\n\n# Import data of the AME/AFE factors and specifications\name_factors <-\n  read.csv(here::here(\"data\",\n                      \"mwi-ihs5-sample-data\",\n                      \"IHS5_AME_FACTORS_vMAPS.csv\")) |>\n  janitor::clean_names()\n\name_spec_factors <-\n  read.csv(here::here(\"data\",\n                      \"mwi-ihs5-sample-data\",\n                      \"IHS5_AME_SPEC_vMAPS.csv\")) |>\n  janitor::clean_names() |>\n  # Rename the population column to cat and select the relevant columns\n  dplyr::rename(cat = population) |>\n  dplyr::select(cat, ame_spec, afe_spec)\n\n\n\nExtra energy requirements for pregnancy\n\n# Extra energy requirements for pregnancy and Illness\npregnantPersons <- ihs5_health |>\n  dplyr::filter(hh_d05a == 28 |\n                  hh_d05b == 28) |> \n  # NOTE: 28 is the code for pregnancy in this survey\n  dplyr::mutate(ame_preg = 0.11, afe_preg = 0.14) |> \n  dplyr::select(HHID, ame_preg, afe_preg)\n\n\n\nProcess HH roster data\n\n# Process the roster data and rename variables to be more intuitive\naMFe_summaries <- ihs5_roster |>\n  # Rename the variables to be more intuitive\n  dplyr::rename(sex = hh_b03, age_y = hh_b05a, age_m = hh_b05b) |>\n  dplyr::mutate(age_m_total = (age_y * 12 + age_m)) |> \n  # Add the AME/AFE factors to the roster data\n  dplyr::left_join(ame_factors, by = c(\"age_y\" = \"age\")) |> \n  dplyr::mutate(\n    ame_base = dplyr::case_when(sex == 1 ~ ame_m, sex == 2 ~ ame_f),\n    afe_base = dplyr::case_when(sex == 1 ~ afe_m, sex == 2 ~ afe_f),\n    age_u1_cat = dplyr::case_when(\n      # NOTE: Round here will ensure that decimals are not omited in the calculation.\n      round(age_m_total) %in% 0:5 ~ \"0-5 months\",\n      round(age_m_total) %in% 6:8 ~ \"6-8 months\",\n      round(age_m_total) %in% 9:11 ~ \"9-11 months\"\n    )\n  ) |>\n  # Add the AME/AFE factors for the specific age categories\n  dplyr::left_join(ame_spec_factors, by = c(\"age_u1_cat\" = \"cat\")) |>\n  # Dietary requirements for children under 1 year old\n  dplyr::mutate(\n    ame_lac = dplyr::case_when(age_y < 2 ~ 0.19),\n    afe_lac = dplyr::case_when(age_y < 2 ~ 0.24)\n  ) |>\n  dplyr::rowwise() |>\n  # TODO: Will it not be better to have the pregnancy values added at the same time here?\n  dplyr::mutate(ame = sum(c(ame_base, ame_spec, ame_lac), na.rm = TRUE),\n                afe = sum(c(afe_base, afe_spec, afe_lac), na.rm = TRUE)) |>\n  # Calculate number of individuals in the households\n  dplyr::group_by(HHID) |>\n  dplyr::summarize(\n    hh_persons = dplyr::n(),\n    hh_ame = sum(ame),\n    hh_afe = sum(afe)\n  ) |>\n  # Merge with the pregnancy and illness data\n  dplyr::left_join(pregnantPersons, by = \"HHID\") |>\n  dplyr::rowwise() |>\n  dplyr::mutate(hh_ame = sum(c(hh_ame, ame_preg), na.rm = T),\n                hh_afe = sum(c(hh_afe, afe_preg), na.rm = T)) |>\n  dplyr::ungroup() |>\n  # Fix single household factors\n  dplyr::mutate(\n    hh_ame = dplyr::if_else(hh_persons == 1, 1, hh_ame),\n    hh_afe = dplyr::if_else(hh_persons == 1, 1, hh_afe)\n  ) |>\n  dplyr::select(HHID, hh_persons, hh_ame, hh_afe) |>\n  dplyr::rename(hhid = HHID)\n\n\n\nEnrich Consumption Data with AFE/AME\nWe will use the left_join function from dplyr to join the consumption data with the aMFe_summaries data.\nThe left_join function will join the aMFe_summaries data to the sample_hces data by matching the hhid column in both data sets.\nThe left_join function will add the hh_persons, hh_ame and hh_afe columns to the sample_hces data.\nThe hh_persons column contains the number of people in each household. The hh_ame and hh_afe columns contain the AME and AFE factors for each household.\n\nsample_hces <- sample_hces |> \n  dplyr::left_join(aMFe_summaries)\n\nNow we have a “clean” data set that we can use for analysis."
  },
  {
    "objectID": "hcesNutR-package.html#summary",
    "href": "hcesNutR-package.html#summary",
    "title": "7  hcesNutR Package",
    "section": "7.6 Summary",
    "text": "7.6 Summary\nThis chapter demonstrated the use of the hcesNutR package to process HCES data. The package contains functions that will help with the analysis of HCES data.\nThe package also contains the sample data used in this book i.e. r4hces-data/mwi-ihs5-sample-data We used this sample data to demonstrate the use of the functions in the package.\nThe package is still under development and will be updated regularly.Please report any bugs or issues here."
  },
  {
    "objectID": "hcesNutR-package.html#future-work",
    "href": "hcesNutR-package.html#future-work",
    "title": "7  hcesNutR Package",
    "section": "7.7 Future work",
    "text": "7.7 Future work\n\nAdd more functions to the package\nSupport more surveys (NGA Living Standards Survey 2018-2019)\nAdd more internal data to the package"
  },
  {
    "objectID": "fct_standardisation.html",
    "href": "fct_standardisation.html",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "",
    "text": "9 Creating the food_group variable in the FCT"
  },
  {
    "objectID": "fct_standardisation.html#introduction",
    "href": "fct_standardisation.html#introduction",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "8.1 Introduction",
    "text": "8.1 Introduction\n\n8.1.1 Selecting food composition data\nWhen selecting the food composition table or database (FCT) that will be used, it is good to reflect on the following questions:\n\nRelevancy for the study/context (e.g., is that FCT/FCBD geographically and culturally close to our survey scope?).\nFCT availability & missing values (e.g., are relevant foods and nutrients reported?).\nData quality and reporting (e.g., what are the method of analysis and metadata available?).\n\n\n\n8.1.2 Objective\nThis document provide, together with the template document, the steps and description for cleaning and standardising FCTs from diverse sources. More details about the cleaned data that can be found in the repository is documented in this folder (documentation).\nFor easy navigation and use of this script it is recommended to use Rstudio. In RStudio please click the “Show Document Outline” button to the right of the source button, at the top right of this window. This will allow for easier navigation of the script."
  },
  {
    "objectID": "fct_standardisation.html#environment-prep",
    "href": "fct_standardisation.html#environment-prep",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "8.2 Environment Prep",
    "text": "8.2 Environment Prep\nFirst we need to check what packages are installed. If you have run this template before in this RStudio project and are sure these packages are already installed, you can comment out (put a hash at the start of) line 20, and skip it.\n\n# Run this to clean the environment\nrm(list = ls())\n\n# Loading libraries\n\nlibrary(readxl) # reading and writing excel files\nlibrary(stringr) # character string handling\nlibrary(dplyr) # cleaning data\nlibrary(here) # file management"
  },
  {
    "objectID": "fct_standardisation.html#obtaining-the-raw-fct-file",
    "href": "fct_standardisation.html#obtaining-the-raw-fct-file",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "8.3 Obtaining the raw (FCT) file",
    "text": "8.3 Obtaining the raw (FCT) file\n\n8.3.1 Data License Check\nBefore using any dataset, we recommend to check licensing conditions & record the data source, you can use the README template.\n\n\n8.3.2 Data Download\nIf the data is publicly available online, usually you only need to run the code below to obtain the raw files. Remember you only need to do it the first time! Then, the data will be stored in the folder of your choice (see below).\nFor instance, many raw files can be found provided by the FAO here, in various formats.\nOnce the link to the data is found, check what file type it is, and paste the direct file link to replace the fill-in value below.\n\n\n8.3.3 File names conventions\nWe advise to use the ISO code (2 digits) (see ISO 3166 2-alpha code for further information) of the country or the region of the FCT scope, plus the two last digits of the year of publication to name, both the folder which will contain the data and the scripts related to the FCT. For instance, Western Africa FCT, 2019 will be coded as WA19. This will help with the interoperability, reusability and findability of the data. Also, to streamline the work in the future. That name convention will be used also as the identifier of the FCT.\nNote that you need to create the folders to store the FCT.\n\nf <- \"https://www.fao.org/fileadmin/user_upload/faoweb/2020/WAFCT_2019.xlsx\"\n \n download.file(f, \n             destfile = here::here(\"data\", # data folder\n                                   'WA19', #FCT folder\n                                   #FCT file\n                                   \"WAFCT_2019.xlsx\"),  \n             method=\"wininet\", #use \"curl\" for OS X / Linux, \"wininet\" for Windows\n             mode=\"wb\")\n\nIf using an RStudio project, and you put the .R file and the data file in the same folder as the RStudio project or within a subfolder, files and folders are much easier to navegate as your project/here::here location automatically moves to the main project folder.\n\nUsing here::here()\n\nA brief introduction to here::here()\nIf you are using an RStudio project but used a different download method, or already have the file you want to process on your computer, or are using base R we can still use the here::here function, however we will have to find the file first. The best practice is to put the file in the same folder as this script, or in a folder within the project. If this is done, then use here::here() to find your current working directory, and then navigate to the file folder. More information about the here package can be found here.\n\n# Run this script to see where is your directory\nhere::here()\n\n\n\nUsing here::here()\nIn order to navigate there, you have to include each subfolder between the here::here location and the file itself (so the ‘data’ folder, the ‘FCT’ folder and the FCT file).\nFind your file in your project, and then direct here::here to it.\n\n# This identifies the file and file path, and saves it as a variable\nFCT_file_location <- here::here('data','WA19', \"WAFCT_2019.xlsx\")"
  },
  {
    "objectID": "fct_standardisation.html#importing-the-data-loading-the-data",
    "href": "fct_standardisation.html#importing-the-data-loading-the-data",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "8.4 Importing the data (loading the data)",
    "text": "8.4 Importing the data (loading the data)\n\nUsing the download code above\nFirst, we must find the file on your system that we want to import. If using RStudio: If you used the download method above Section 1.2 then we will see the same location as specified there to specify the file. Simply copy the contents of the here::here brackets and use it to fill the here::here brackets in the line of code below.\n\n\n8.4.1 Importing Files\nFCT files come in many different forms - the most common being “.xlsx” files and “.csv” files. Methods to import both of these file types will be covered - please navigate to the relevant subsection.\nDuring import, a identifier for the FCT is created and added to the table. Please replace ‘WA19’ from the next code chunck with the FCT id., comprised of the countries ISO 3166 2-alpha code, and the year the FCT was produced (e.g. for the Western Africa FCT from 2019, the reference would be ‘MWA9’). This should be the same as the folder name explained in (section 1.3)[link-to-section].\n\n# This is an example of the name \nFCT_id <- 'WA19' # Change two first letter for your ISO 2 code & the two digits for the last two digits of the year of publication.\n\n\nImporting .xlsx files\nFor the excel-type of files, first, you need to check what information is provided and which of the sheet is providing the FC data.\n\n# Checking the sheets\n\nreadxl::excel_sheets(FCT_file_location)\n\ndata.df <- readxl::read_excel(FCT_file_location, #The file location, as                            identified in section 2.1\n                              sheet = 5  # Change to the excel sheet where                              the FCT is stored in the excel file\n                              ) %>%  \n  mutate(source_fct = FCT_id)  #Creates the source_fct column and fills with                 a id for this FCT, as filled in in section 2.2. \n\n\n\nImporting .csv files\n\ndata.df <- read.csv2(FCT_file_location, #The file location, as identified in section 2.1\n                     sep = \",\") %>%  # Replace w/ other symbol if needed\n  mutate(source_fct = FCT_id) #Creates the source_fct column and fills with a id for this FCT, as filled in in section 2.2. \n\nOnce imported, it is important to check the data.frame created from the csv, by using head(data.df) or clicking on its entry in the Environment panel of RStudio (This second option is not advised with very large files, however, as it can be slow).\nIf the data shown by doing this has all its columns combined, with a symbol in-between, then that symbol (e.g. ‘;’) is the separator for that csv. Replace comma in the sep = \",\" line from the code block above with the new symbol, and run the entire block again.\n\n\nVisually checking the data\n\n# Checking the dataframe\nhead(data.df) \n\n\n\nChecking the loaded data\n\n\n\n\n\n\nQuestion\n\n\n\nHow many rows & columns have the data?\n\n\nYou can use the function dim() to answer to check the number of rows and column.\n\ndim(data.df) # rows & columns\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\nOther useful functions to evaluate the structure of the data are:\n\n# Structure (variable names, class, etc.)\nstr(data.df)\n\n# Checking the last rows and columns\ntail(data.df) \n\nFor opening the dataframe in a tab, you can use View(data.df).\nNote: if the dataset is very very big, may crash the R session.\nAfter checking that the correct FCT file have loaded the, then proceed. If not, find the correct file and import it instead."
  },
  {
    "objectID": "fct_standardisation.html#cleaning-tidying-and-standardising-the-data",
    "href": "fct_standardisation.html#cleaning-tidying-and-standardising-the-data",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "8.5 Cleaning (tidying) and standardising the data",
    "text": "8.5 Cleaning (tidying) and standardising the data\n\n8.5.1 Formatting FCT into a tabular format\n\nTrimming dataframe rows\nRunning this will trim down the table to only include the row numbers between x and y - replace x and y with your desired values. If you wanted to include multiple row ranges, that is also possible - use comments to differentiate between different row ranges and individual rows. e.g. if you wanted to include rows a:b, row c, row e, and rows g:x, then the code would be slice(a:b, c, e, g:x).\n\ndata.df %>% slice(1:5) %>% knitr::kable()\n\n\n\nTrimming dataframe columns\nIf you only wish to include certain columns/nutrients, then you might wish to remove the unnecessary columns to make the dataframe easier to read and manage. This can be done through 2 methods; either by selecting the names of the columns you want to keep, or by selecting the names of the columns you want to remove.\n\n\nKeep specified columns only\nThis method requires creating a list of column names you want to keep - for #example the line below would select the columns ‘Energy_kcal’, ‘Fatg’, ‘Protein_g’, but nothing else. If you wish to trim the columns this way, replace the items in the first line with the column names you want to keep, then run the code block below.\n\n# Storing the variables you want to keep\ncolumns_to_keep <- c('Scientific name', 'Energy\\r\\n(kJ)')\n\n# Selecting the variables\ndata.df %>% select(columns_to_keep) %>% \n  head(5) %>% \n  knitr::kable()\n\n\n\nRemove specified columns, keep all others\nSometimes it is easier to list the columns you want to remove, rather than the ones you want to keep. The code block below identifies the columns to be removed (‘VitB12_mcg’ and ‘Calcium_mg’ in the example), and then removes them. If you wish to trim the columns this way, replace the items in the first line with the column names you want to remove, then run the code block below.\nThis works in a similar way to the codeblock in section 3.3.1, however by putting an exclamation mark (!) before the list of columns, it inverts the selection - instead of instructing R to keep only the listed columns (as with the codeblock above), it instructs R to keep all columns but the listed ones.\n\n# Selecting the variables that you don't want to keep\ncolumns_to_remove <- c('Food name in French', 'Sum of proximate components\\r\\n(g)') \n\ndata.df %>% select(!columns_to_remove) %>% \n  head(5) %>% \n  knitr::kable()\n\n\n\n\n8.5.2 Creating food groups variable and tidying\nSome food composition tables reported food groups that were placed as the first row of each category, however that it is not a data structure that can be used, as we need one column per variable. Hence, the food group names are extracted from the rows, and are allocated as a new attribute of each food (e.g., fish and fishery products to catfish). The food groups are stored in a new column (food_group).\nThis process requires multiple steps, each covered in their own subsections below: Extracting food group names, Creating the variable, and checking changes in the structure.\n\nExtracting food group names\n\n#Creates a list of the food groups using their unique row structure in the table to identify them\n\nfgroup <- data.df %>% \n  filter(is.na(`Food name in English`), !is.na(Code)) %>%\n  pull(Code) %>%\n  stringr::str_split_fixed( '/', n = 2) %>% \n  as_tibble() %>%\n  pull(V1) \n\ngroup.id <-  unique(str_extract(data.df$Code, \"^[:digit:]{2}\\\\_\"))[-1]"
  },
  {
    "objectID": "fct_standardisation.html#further-readings",
    "href": "fct_standardisation.html#further-readings",
    "title": "8  Food Composition Table & Databases: Standardisation",
    "section": "9.1 Further readings",
    "text": "9.1 Further readings\n\nCharrondiere, U.R., Stadlmayr, B., Grande, F., Vincent, A., Oseredczuk, M., Sivakumaran, S., Puwastien, P., Judprasong, K., Haytowitz, D., Gnagnarella, P. 2023. FAO/INFOODS Evaluation framework to assess the quality of published food composition tables and databases - User guide. Rome, FAO. https://doi.org/10.4060/cc5371en"
  },
  {
    "objectID": "sample_data.html#introduction",
    "href": "sample_data.html#introduction",
    "title": "11  Appendix A: Sample Data",
    "section": "11.1 Introduction",
    "text": "11.1 Introduction\nThe sample data used in this book was generated from the Malawi Intergrated Household Survey Fifth Edition 2018-2019 downloaded from here.\nThe data was generated randomly using the following code:"
  },
  {
    "objectID": "sample_data.html#define-functions-used",
    "href": "sample_data.html#define-functions-used",
    "title": "11  Appendix A: Sample Data",
    "section": "11.2 Define functions used",
    "text": "11.2 Define functions used\n\n11.2.1 Create case_id generation\n\ngenerate_case_ids <- function(n) {\n    start_id <- 201011000001\n    end_id <- start_id + n-1\n    case_ids <- as.character(seq(start_id, end_id, by = 1))\n    return(case_ids)\n}\n\n\n\n11.2.2 Create HHID generation function\n\ngenerate_HHIDs <- function(n) {\n  hhids <- sapply(1:n, function(x) {\n    paste(sample(c(0:9, letters[1:6]), 32, replace = TRUE), collapse = \"\")\n  })\n  return(hhids)\n}"
  },
  {
    "objectID": "sample_data.html#set-seed-and-number-of-households-to-generate",
    "href": "sample_data.html#set-seed-and-number-of-households-to-generate",
    "title": "11  Appendix A: Sample Data",
    "section": "11.3 Set seed and number of households to generate",
    "text": "11.3 Set seed and number of households to generate\n\n# Set seed\nset.seed(123)\n# Set number of households to generate\nhouseholds <- 100"
  },
  {
    "objectID": "sample_data.html#load-original-data-and-extract-food-and-unit-lists",
    "href": "sample_data.html#load-original-data-and-extract-food-and-unit-lists",
    "title": "11  Appendix A: Sample Data",
    "section": "11.4 Load Original data and extract food and unit lists",
    "text": "11.4 Load Original data and extract food and unit lists\n\n# Import Malawi IHS5 HCES consumption module data\noriginal_data <-\n  haven::read_dta(here::here(\"data-ignore\", \"IHS5\", \"HH_MOD_G1.dta\"))\n\n# Extract \"standard\" food list from the original data\nfood_list <-\n  original_data |> \n  dplyr::select(hh_g02) |> \n  dplyr::distinct()\n\n# Extract \"non-standard\" food lists from the original data\nother_food_list_codes <-\n  original_data |> \n  dplyr::distinct(hh_g02, hh_g01_oth) |> \n  dplyr::filter(hh_g01_oth != \"\") |> \n  dplyr::distinct(hh_g02) |> \n  dplyr::arrange()\nother_food_list_options <-\n  original_data |> \n  dplyr::distinct(hh_g02, hh_g01_oth) |> \n  dplyr::filter(hh_g01_oth != \"\")\n\n# Extract Food unit lists from the original data\nfood_unit_lists <-\n  original_data |> \n  dplyr::distinct(hh_g03b, hh_g03b_label, hh_g03b_oth, hh_g03c, hh_g03c_1)\n\n# Extract the length of Number of foods from the food list\nn_foods <- length(food_list$hh_g02)"
  },
  {
    "objectID": "sample_data.html#data-creation",
    "href": "sample_data.html#data-creation",
    "title": "11  Appendix A: Sample Data",
    "section": "11.5 Data creation",
    "text": "11.5 Data creation\n\n11.5.1 Create HHIDs\n\n# Creeate case_ids\ncase_id <- generate_case_ids(households)\n# Generate HHIDs\nhhids <- generate_HHIDs(households)\n\n\n\n11.5.2 Create data\n\nsample_data <- tibble::tibble(\n  case_id = rep(case_id, each = n_foods),\n  HHID = rep(hhids, each = n_foods),\n      hh_g00_1 = 2,\n    hh_g00_2 = 2,\n  food_list |> dplyr::slice(rep(1:dplyr::n(), households)),\n      hh_g01 = sample(\n      original_data$hh_g01,\n      # replace = T,\n      size = households * 142\n    )\n  ) |>\n\n# Add \"other food items\"\n\n  dplyr::rowwise() |>\n  dplyr::mutate(\n    hh_g01_oth = dplyr::case_when(\n      hh_g02 == 414 &\n        hh_g01 == 1 ~ sample(\n          dplyr::filter(other_food_list_options,hh_g02 == 414) |> dplyr::pull(hh_g01_oth),\n          1\n        ),\n      hh_g02 == 515 &\n        hh_g01 == 1  ~ sample(\n          dplyr::filter(other_food_list_options,hh_g02 == 515) |> dplyr::pull(hh_g01_oth),\n          1\n        ),\n      hh_g02 == 117 &\n        hh_g01 == 1  ~ sample(\n          dplyr::filter(other_food_list_options,hh_g02 == 117) |> dplyr::pull(hh_g01_oth),\n          1\n        ),\n      hh_g02 == 830 &\n        hh_g01 == 1  ~ sample(\n          dplyr::filter(other_food_list_options,hh_g02 == 830) |> dplyr::pull(hh_g01_oth),\n          1\n        ),\n      hh_g02 == 310 &\n        hh_g01 == 1  ~ sample(\n          dplyr::filter(other_food_list_options,hh_g02 == 310) |> dplyr::pull(hh_g01_oth),\n          1\n        ),\n      hh_g02 == 412 &\n        hh_g01 == 1  ~ sample(\n          dplyr::filter(other_food_list_options,hh_g02 == 412) |> dplyr::pull(hh_g01_oth),\n          1\n        ),\n      hh_g02 == 610 &\n        hh_g01 == 1  ~ sample(\n         dplyr::filter( other_food_list_options,hh_g02 == 610) |> dplyr::pull(hh_g01_oth),\n          1\n        ),\n      hh_g02 == 916 &\n        hh_g01 == 1  ~ sample(\n          dplyr::filter(other_food_list_options,hh_g02 == 916) |> dplyr::pull(hh_g01_oth),\n          1\n        ),\n      hh_g02 == 209 &\n        hh_g01 == 1  ~ sample(\n          dplyr::filter(other_food_list_options,hh_g02 == 209) |> dplyr::pull(hh_g01_oth),\n          1\n        ),\n      hh_g02 == 709 &\n        hh_g01 == 1  ~ sample(\n          dplyr::filter(other_food_list_options,hh_g02 == 709) |> dplyr::pull(hh_g01_oth),\n          1\n        ),\n      hh_g02 == 818 &\n        hh_g01 == 1  ~ sample(\n           dplyr::filter(other_food_list_options,hh_g02 == 818) |> dplyr::pull(hh_g01_oth),\n          1\n        ),\n      hh_g02 == 804 &\n        hh_g01 == 1  ~ sample(dplyr::filter(other_food_list_options,hh_g02 == 804) |> dplyr::pull(hh_g01_oth),\n          1\n        ),\n      TRUE ~ \"\"\n    )\n  ) |>\n  dplyr::mutate(hh_g03a = dplyr::case_when(hh_g01 == 1 ~ sample(c(1:10, 0.5:10), 1),\n                                           TRUE ~ NA)) |>\n  dplyr::rowwise() |>\n  dplyr::mutate(unit_key = dplyr::case_when(hh_g01 == 1 ~ sample(1:214, 1), TRUE ~\n                                              NA)) |>\n  dplyr::mutate(\n    hh_g03b = food_unit_lists$hh_g03b[unit_key],\n    hh_g03b_label = food_unit_lists$hh_g03b_label[unit_key],\n    hh_g03b_oth = food_unit_lists$hh_g03b_oth[unit_key],\n    hh_g03c = food_unit_lists$hh_g03c[unit_key],\n    hh_g03c_1 = food_unit_lists$hh_g03c_1[unit_key]\n  ) |>\n  dplyr::select(\n    -unit_key,\n    \"case_id\",\n    \"HHID\",\n    \"hh_g00_1\",\n    \"hh_g00_2\",\n    \"hh_g01\",\n    \"hh_g01_oth\",\n    \"hh_g02\",\n    \"hh_g03a\",\n    \"hh_g03b\",\n    \"hh_g03b_label\",\n    \"hh_g03b_oth\",\n    \"hh_g03c\",\n    \"hh_g03c_1\"\n  ) \n\n\n# Add the rest of the columns\nsample_data <- original_data |> dplyr::filter(is.na(case_id)) |> \ndplyr::bind_rows(sample_data)\n\n\n# Attach stata column labels\nfor (i in names(sample_data)){\n  attr(sample_data[[i]], \"label\") <- attr(original_data[[i]], \"label\")\n}\n\n\n# Export sample data as stata file\nhaven::write_dta(sample_data,here::here(\"data\",\"sample_data\",\"MWI-IHSV\",\"HH_MOD_G1_vMAPS.dta\"))\n\n\n\n11.5.3 Create hh_mod_a_filt.dta file\n\nsample_data |> \ndplyr::select(case_id,HHID) |> \ndplyr::distinct() |> \ndplyr::rowwise() |>\ndplyr::mutate(region = sample(1:3,1)) |> \nhaven::write_dta(here::here(\"data\",\"sample_data\",\"MWI-IHSV\",\"hh_mod_a_filt_vMAPS.dta\"))\n\n\n\n11.5.4 Create hh_roster.dta\n\n# Import original roster from IHS5\nihs5_roster <- haven::read_dta(here::here(\"data-ignore\", \"IHS5\", \"HH_MOD_B.dta\"))\n\n# create a dataframe with the case_ids and HHIDs of our sample data\nsample_roster <- sample_data |> dplyr::distinct(case_id,HHID)\n\n# replicate each row a random number of times between 1 and 10 to simulate household members\nn <- sample(1:10, nrow(sample_roster), replace = TRUE)\nsample_roster <- sample_roster[rep(seq_len(nrow(sample_roster)), times = n), ]\n\n# Create other variables\nsample_roster <- sample_roster |> \ndplyr::rowwise() |>\ndplyr::mutate(hh_b03 = sample(ihs5_roster$hh_b03,1),\nhh_b05a = sample(ihs5_roster$hh_b05a,1),\nhh_b05b = dplyr::case_when(hh_b05a < 5~sample(1:11,1),TRUE~NA))\n\n# Add the other blank columns from the original dataset\nsample_roster <- ihs5_roster |>\ndplyr::filter(case_id == \"\") |>\ndplyr::bind_rows(sample_roster)\n\n# Attach stata column labels\nfor (i in names(sample_roster)){\n  attr(sample_roster[[i]], \"label\") <- attr(ihs5_roster[[i]], \"label\")\n}\n\n# writeout the sample_ihs5_roster\nhaven::write_dta(sample_roster,here::here(\"data\",\"sample_data\",\"MWI-IHSV\",\"HH_MOD_B_vMAPS.dta\"))\n\n\n\n11.5.5 Create sample “HH_MOD_D.dta”\n\n# import original data\noriginal_health <- haven::read_dta(here::here(\"data-ignore\", \"IHS5\", \"HH_MOD_D.dta\"))\n\n# Use the sample_roster to create a sample_health dataset\nsample_health <- sample_roster |>\ndplyr::select(case_id,HHID) |>\ndplyr::rowwise()|>\ndplyr::mutate(hh_d05a = sample(c(original_health$hh_d05a),1),\nhh_d05b = sample(original_health$hh_d05b,1))\n\n# Add the other blank columns from the original dataset\nsample_health <- original_health |>\ndplyr::filter(case_id == \"\") |>\ndplyr::bind_rows(sample_health)\n\n# Attach stata column labels\nfor (i in names(sample_health)){\n  attr(sample_health[[i]], \"label\") <- attr(sample_health[[i]], \"label\")\n}\n\n# writeout the sample_ihs5_roster\nhaven::write_dta(sample_health,here::here(\"data\",\"sample_data\",\"MWI-IHSV\",\"HH_MOD_D_vMAPS.dta\"))"
  },
  {
    "objectID": "fct_harmonisation.html#introduction",
    "href": "fct_harmonisation.html#introduction",
    "title": "9  Food composition harmonisation and food matching",
    "section": "9.1 Introduction",
    "text": "9.1 Introduction\n\n9.1.1 Food matching\nAfter the FCTs are standardised and harmonised and the food list (i.e., food reported as consumed in the Integrated Household Survey, Wave 5, 2019-2020), we can proceed to match them together. To do so, we are using a standardised list of foods that we called “food dictionary”. As depicted in the ?fig-matching.\n\n\n\n9.1.2 Further Readings\n\n\nGreenfield, Heather, and D. A. T. Southgate. Food Composition Data: Production, Management, and Use. Rome: FAO, 2003.\nFAO/INFOODS (2012). FAO/INFOODS Guidelines for Checking Food Composition Data Prior to the Publication of a User Table/Database-Version 1.0. FAO, Rome’. Accessed 22 January 2022. https://www.fao.org/3/ap810e/ap810e.pdf."
  },
  {
    "objectID": "fct_harmonisation.html#harmonising-the-food-composition-tables",
    "href": "fct_harmonisation.html#harmonising-the-food-composition-tables",
    "title": "9  Food composition harmonisation and food matching",
    "section": "9.2 Harmonising the Food Composition Tables",
    "text": "9.2 Harmonising the Food Composition Tables\nWhen all the FCTs are standardised, we can use them all together, which is particularly useful when food items and/or nutrient values are missing in the main FCT, then a similar food item could be found in another FCT."
  },
  {
    "objectID": "fct_harmonisation.html#getting-the-nutrition-tools",
    "href": "fct_harmonisation.html#getting-the-nutrition-tools",
    "title": "9  Food composition harmonisation and food matching",
    "section": "9.3 Getting the Nutrition Tools",
    "text": "9.3 Getting the Nutrition Tools\nNutritionTools is an R package of functions to help with a wide range of calculations and processes that commonly occur when working with nutrition datasets. More information can be found here.\n\nif (!require(\"devtools\")) {\n  install.packages(\"devtools\")\n}\ndevtools::install_github(\"TomCodd/NutritionTools\")\n\n\n9.3.1 Food composition functions\nThere are some useful functions that can be downloaded here, and are currently being checked to be added to the NutritionTool package. Those can be loaded into the R environment by running the functions.R script.\n\n# We also need to import some custom functions in another script:\nsource(here::here(\"functions.R\")) # Loading nutrition functions\n\nThe function source() will run the called script."
  },
  {
    "objectID": "fct_harmonisation.html#getting-the-fc-standardarised-dataset",
    "href": "fct_harmonisation.html#getting-the-fc-standardarised-dataset",
    "title": "9  Food composition harmonisation and food matching",
    "section": "9.4 Getting the FC Standardarised dataset",
    "text": "9.4 Getting the FC Standardarised dataset\nDownload the following folders: KE18 & WA19 from this GitHub repository. Eventually, you could download all of them an create a unique FC library.\nEach folder has one script with the FCT id followed by *“_FCT_FAO_Tags”*, and a README file.\n\n# Finding the list of FCTs/FCDBs script in the data folder\n\nlist.files(\"data/\", pattern = \"*_FCT_FAO_Tags\", recursive=FALSE, # so it is not looking into the subfolders\n           full.names=TRUE)\n\nThe next block of code will download and standardise each individual FCT. Then, the FCTs are merged into a common FC library that can be used for food matching.\n\n# Getting the list of FCTs/FCDBs script in the data folder\nsource_fct_name <- list.files(\"data/\", pattern = \"*_FCT_FAO_Tags.R\", recursive=FALSE, # so it is not looking into the subfolders\n           full.names=TRUE)\n\nfor(i in source_fct_name){\n  source(here::here(i))\n}\n\n\n9.4.1 Merging the data\nChecking the FCT we have in our data folder\n\n# finding all the cleaned FCTs/FCDBs from the output folder\nlist.files(\"data/\", pattern = \"*_FCT_FAO_Tags\", recursive=FALSE, # so it is not looking into the subfolders.\n           full.names=TRUE)\n\nNow, we can merge all the FCTs/FCBDs into one file. Note that this is posible because they all have been standardised previously.\n\n# finding all the cleaned FCTs/FCDBs from the output folder\nlist.files(\"data/\", pattern = \"*_FCT_FAO_Tags\", recursive=FALSE, # so it is not taking the fcts in the folder\n           full.names=TRUE)%>% \n  map_df(~read_csv(., col_types = cols(.default = \"c\"), \n                   locale = locale(encoding = \"Latin1\"))) \n\nWe can check that all FCTs that we are expected are there, by using the source_fct variable that is generated within the standardisation scripts, and the number of foods in each one.\n\n#checking that all FCTs are loaded and \n# counting No. of items \n\ndata.df %>%  \n  count(source_fct)"
  },
  {
    "objectID": "fct_harmonisation.html#food-matching-1",
    "href": "fct_harmonisation.html#food-matching-1",
    "title": "9  Food composition harmonisation and food matching",
    "section": "9.5 Food matching",
    "text": "9.5 Food matching\nFirst, we need the list of unique foods reported as consumed. In HCES dataset, this is frequently presented as set of standard list of foods. We are also interested in knowing the frequency with each food is reported, and hence their impact and importance for subsequent analysis.\n\n# Read, subset and rename the data\nihs5_consumption <-\n    read_dta(here::here(\"data\", \"mwi-ihs5-sample-data\", \"HH_MOD_G1_vMAPS.dta\")) |>\n    select(\n        case_id,\n        HHID,\n        hh_g01,\n        hh_g01_oth,\n        hh_g02,\n        hh_g03a,\n        hh_g03b,\n        hh_g03b_label,\n        hh_g03b_oth,\n        hh_g03c,\n        hh_g03c_1\n    ) %>%\n    rename(\n        consumedYN = hh_g01,\n        food_item = hh_g02,\n        food_item_other = hh_g01_oth,\n        consumption_quantity = hh_g03a,\n        consumption_unit = hh_g03b,\n        consumption_unit_label = hh_g03b_label,\n        consumption_unit_oth = hh_g03b_oth,\n        consumption_subunit_1 = hh_g03c,\n        consumption_subunit_2 = hh_g03c_1\n    )\n\n\n# Getting the food item list\n\nihs5_consumption <- hcesNutR::create_dta_labels(ihs5_consumption)\n\n\n# Getting the food list & frequency of HH\n\nfood_list <- ihs5_consumption %>%\n  count(food_id, food_item)\n\nThen, we will match those food items with their corresponding food dictionary code(s). There are instances were the matching will be one food reported to many foods in the FCT. For example, wheat flour will be matched to wheat flour refined, and wheat flour wholemeal.\n\n# Food dictionary\nread.csv(\"https://raw.github.com/LuciaSegovia/fct/repro/metadata/MAPS_food-dictionary_v3.0.3.csv\")\n\nThen, the unique food dictionary codes (ID_3) will be used to match the food in the food list to the FCTs.\n\n# Matching \n\nread.csv(here::here(\"data\", \"fct_ihs5_v2.2.csv\"))\n\n\n\n\n\n\n\nActivity:\n\n\n\nThinking about food matches between HCES food list and food composition.\n\nDo you think that the food matches selected represents well what the food reported as consumed in the survey?\nIf not, what other foods would you add/remove/change to?\nFor the foods without matches, can you think of what food items you would use?\nCould you identify any food matches in the Food Composition Library that will be a good match for those foods that have no matches?\nWhat nutrients are important for each of the foods selected?"
  },
  {
    "objectID": "fct_harmonisation.html#dealing-with-missing-values",
    "href": "fct_harmonisation.html#dealing-with-missing-values",
    "title": "9  Food composition harmonisation and food matching",
    "section": "9.6 Dealing with missing values",
    "text": "9.6 Dealing with missing values\n\n9.6.1 Combining Tagnames to generate variables\n\n\n9.6.2 Re-calculating variables\nSome varibles need to be recalculated, as part of the harmonisation process and also for quality assurance. One case is Energy (kcal/kJ) which is calculated from the proximate: Protein, Fat, available Carbohydrates, Fibre and Alcohol. Hence, we need to make sure that all these variables are reported and are completed. For instance, if there were missing values in Fat content, that the combination of Tagnames have been performed. In addition, if we are using Carbohydrate by difference, then we should re-calculate that variable as well.\n\n# Re-calculate variables:\ndata.df %>% \n  # Calculate available Carbohydrates, by difference\n  CHOAVLDFg_std_creator() %>%  \n  # Calculate Energy (kcal)\n  ENERCKcal_standardised() %>% \n  # calculate Energy (kJ)\n  ENERCKj_standardised() \n\nAnother similar example is Vitamin A (RE/RAE), which is calculated from retinol and the carotenoids (i.e., Beta-carotene equivalents). Similarly, we need to check that those two variables. Note, that beta-carotene eq. is also re-calculated, when possible, from the carotenids and their conversion factors. Hence, first we should check that beta-carotene, alpha-carotene, and beta-crypoxanthin are available.\n\n# Re-calculate variables:\ndata.df %>% \n# Recalculate beta-carotene eq.\n    CARTBEQmcg_std_creator() %>% \n# Recalculate Vitamin A (RAE)\n   VITA_RAEmcg_std_creator() %>%  \n# Recalculate Vitamin A (RE)\n    VITAmcg_std_creator()"
  },
  {
    "objectID": "fct_harmonisation.html#visualisation-qc",
    "href": "fct_harmonisation.html#visualisation-qc",
    "title": "9  Food composition harmonisation and food matching",
    "section": "9.7 Visualisation & QC",
    "text": "9.7 Visualisation & QC"
  }
]